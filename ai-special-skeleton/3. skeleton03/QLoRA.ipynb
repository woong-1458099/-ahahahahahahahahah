{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XVl6yF8wXZy2",
    "outputId": "7432775d-338b-4a65-cc81-f8346fb553df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.49.2)\n",
      "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.10.0+cu128)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (26.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.3.0)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch<3,>=2.3->bitsandbytes) (1.3.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (26.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.10.0+cu128)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (1.4.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.24.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.3)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (0.24.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch>=2.0.0->accelerate) (1.3.4)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (4.12.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (0.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface_hub>=0.21.0->accelerate) (0.24.0)\n",
      "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface_hub>=0.21.0->accelerate) (8.3.1)\n",
      "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface_hub>=0.21.0->accelerate) (13.9.4)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface_hub>=0.21.0->accelerate) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface_hub>=0.21.0->accelerate) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface_hub>=0.21.0->accelerate) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface_hub>=0.21.0->accelerate) (0.1.2)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers) (0.24.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (3.24.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers) (0.24.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
      "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (8.3.1)\n",
      "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (13.9.4)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "# 묻지도 따지지도 않고 필요한 압축 도구들을 강제로 설치합니다!\n",
    "!pip install -U bitsandbytes\n",
    "!pip install -U accelerate\n",
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBMRC-8eG2Fh"
   },
   "source": [
    "### **Objectives**\n",
    "\n",
    "1. 실습명 : QLoRA로 모델을 양자화해서 학습하기기\n",
    "2. 핵심 주제:\n",
    "    1. 데이터셋 불러오기\n",
    "    2. base 모델 4 bit 양자화 및 토크나이저 불러오기\n",
    "    3. Text-to-SQL task 모델 QLoRA fine-tuning\n",
    "3. 학습 목표 :\n",
    "    1. Text-to-SQL task 학습을 위한 4 bit base 모델 및 토크나이저를 불러올 수 있다.\n",
    "    2. base 모델에 QLoRA를 이용하여 4-bit 양자화 fine-tuning을 진행할 수 있다.\n",
    "4. 학습 개념: 키워드명 :\n",
    "    1. bitsandbytes\n",
    "    2. 4-bit\n",
    "    3. QLoRA fine-tuning\n",
    "5. 학습 방향 :\n",
    "  - 양자화라는 개념을 이해하고 이를 통해 모델의 성능 하락을 최소화하면서 모델을 학습합니다.\n",
    "  - 실습 코드는 조교가 직접 구현한 코드를 참고하여 학습합니다.\n",
    "  - 해당 실습은 모델을 학습시킬 경우 무엇이 필요하고 어떻게 하면 학습을 효율적으로 할 수 있는지 고민해봅니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAInghRQRD4h"
   },
   "source": [
    "### **Prerequisites**\n",
    "```\n",
    "numpy==2.1.0\n",
    "pandas==2.2.3\n",
    "transformers==4.56.0\n",
    "torch==2.8.0+cu126\n",
    "accelerate==1.10.1\n",
    "bitsandbytes==0.49.1\n",
    "datasets==4.0.0\n",
    "peft==0.17.1\n",
    "trl==0.22.2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qe9sE9bDRD4i"
   },
   "source": [
    "랜덤성을 제어하기 위해 seed를 고정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "UXrsTMkd01i-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# tqdm이 텍스트 모드를 사용하도록 설정 (ipywidgets 에러 방지)\n",
    "os.environ[\"TQDM_DISABLE\"] = \"0\"\n",
    "os.environ[\"TQDM_MININTERVAL\"] = \"1\"\n",
    "\n",
    "# 시드 설정\n",
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAtkiAVNRD4j"
   },
   "source": [
    "GPU가 인식이 되고 있는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44mSkNBoRD4j",
    "outputId": "bf48f56f-2de8-405d-d6f7-60caf2eb5812"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())  # True/False 반환\n",
    "# device 설정\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-_D1uG2G67l"
   },
   "source": [
    "# 1. 데이터셋 불러오기 및 EDA\n",
    "\n",
    "- 학습 목표 : 데이터셋을 불러올 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mk1Fi9wMTo-"
   },
   "source": [
    "첨부한 데이터셋을 불러옵니다. 데이터셋은 이전 강의에서 사용한 데이터셋과 동일합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "ZD1ZxAduG8ra",
    "outputId": "c92cf2b1-439d-4189-b280-d281cf7846ad"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 7000,\n  \"fields\": [\n    {\n      \"column\": \"db_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 140,\n        \"samples\": [\n          \"manufactory_1\",\n          \"icfp_1\",\n          \"customers_and_invoices\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3964,\n        \"samples\": [\n          \"SELECT Nominee ,  COUNT(*) FROM musical GROUP BY Nominee\",\n          \"SELECT DISTINCT Hometown FROM people EXCEPT SELECT DISTINCT T2.Hometown FROM gymnast AS T1 JOIN people AS T2 ON T1.Gymnast_ID  =  T2.People_ID\",\n          \"SELECT fname ,  lname FROM employee WHERE salary  >  30000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6962,\n        \"samples\": [\n          \"Count the number of classrooms in Lamberton.\",\n          \"What is the last name of every student who is either female or living in a city with the code BAL or male and under 20?\",\n          \"Show ids of students who play video game and play sports.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "train_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-3a698685-e6d5-4ce4-b539-75c33a1ae6af\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>db_id</th>\n",
       "      <th>query</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>department_management</td>\n",
       "      <td>SELECT count(*) FROM head WHERE age  &gt;  56</td>\n",
       "      <td>How many heads of the departments are older th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>department_management</td>\n",
       "      <td>SELECT name ,  born_state ,  age FROM head ORD...</td>\n",
       "      <td>List the name, born state and age of the heads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>department_management</td>\n",
       "      <td>SELECT creation ,  name ,  budget_in_billions ...</td>\n",
       "      <td>List the creation year, name and budget of eac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>department_management</td>\n",
       "      <td>SELECT max(budget_in_billions) ,  min(budget_i...</td>\n",
       "      <td>What are the maximum and minimum budget of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>department_management</td>\n",
       "      <td>SELECT avg(num_employees) FROM department WHER...</td>\n",
       "      <td>What is the average number of employees of the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a698685-e6d5-4ce4-b539-75c33a1ae6af')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-3a698685-e6d5-4ce4-b539-75c33a1ae6af button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-3a698685-e6d5-4ce4-b539-75c33a1ae6af');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                   db_id                                              query  \\\n",
       "0  department_management         SELECT count(*) FROM head WHERE age  >  56   \n",
       "1  department_management  SELECT name ,  born_state ,  age FROM head ORD...   \n",
       "2  department_management  SELECT creation ,  name ,  budget_in_billions ...   \n",
       "3  department_management  SELECT max(budget_in_billions) ,  min(budget_i...   \n",
       "4  department_management  SELECT avg(num_employees) FROM department WHER...   \n",
       "\n",
       "                                            question  \n",
       "0  How many heads of the departments are older th...  \n",
       "1  List the name, born state and age of the heads...  \n",
       "2  List the creation year, name and budget of eac...  \n",
       "3  What are the maximum and minimum budget of the...  \n",
       "4  What is the average number of employees of the...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "text_to_sql = load_dataset('csv', data_files={\n",
    "    'train': '/content/train.csv',\n",
    "    'test': '/content/validation.csv'\n",
    "})\n",
    "train_df = text_to_sql[\"train\"].to_pandas()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itJndFrwgob_"
   },
   "source": [
    "저희의 목표는 자연어(text)를 SQL로 변환하는 Text-to-SQL 모델을 학습하는 것입니다. 불필요한 데이터는 제거하고, 필요한 데이터만을 사용하여 학습을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "IH-SQeovgob_",
    "outputId": "733ad315-9cbd-4a16-d753-50fc2a8c9f3b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 7000,\n  \"fields\": [\n    {\n      \"column\": \"query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3964,\n        \"samples\": [\n          \"SELECT Nominee ,  COUNT(*) FROM musical GROUP BY Nominee\",\n          \"SELECT DISTINCT Hometown FROM people EXCEPT SELECT DISTINCT T2.Hometown FROM gymnast AS T1 JOIN people AS T2 ON T1.Gymnast_ID  =  T2.People_ID\",\n          \"SELECT fname ,  lname FROM employee WHERE salary  >  30000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6962,\n        \"samples\": [\n          \"Count the number of classrooms in Lamberton.\",\n          \"What is the last name of every student who is either female or living in a city with the code BAL or male and under 20?\",\n          \"Show ids of students who play video game and play sports.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "train_data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-e9d1c8ee-f7cb-4f45-a9fd-dd13c9cebad7\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SELECT count(*) FROM head WHERE age  &gt;  56</td>\n",
       "      <td>How many heads of the departments are older th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SELECT name ,  born_state ,  age FROM head ORD...</td>\n",
       "      <td>List the name, born state and age of the heads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SELECT creation ,  name ,  budget_in_billions ...</td>\n",
       "      <td>List the creation year, name and budget of eac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SELECT max(budget_in_billions) ,  min(budget_i...</td>\n",
       "      <td>What are the maximum and minimum budget of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SELECT avg(num_employees) FROM department WHER...</td>\n",
       "      <td>What is the average number of employees of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>SELECT T1.company_name FROM culture_company AS...</td>\n",
       "      <td>What are all the company names that have a boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>SELECT T1.title ,  T3.book_title FROM movie AS...</td>\n",
       "      <td>Show the movie titles and book titles for all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>SELECT T1.title ,  T3.book_title FROM movie AS...</td>\n",
       "      <td>What are the titles of movies and books corres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>SELECT T2.company_name FROM movie AS T1 JOIN c...</td>\n",
       "      <td>Show all company names with a movie directed i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>SELECT T2.company_name FROM movie AS T1 JOIN c...</td>\n",
       "      <td>What are all company names that have a corresp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 2 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9d1c8ee-f7cb-4f45-a9fd-dd13c9cebad7')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-e9d1c8ee-f7cb-4f45-a9fd-dd13c9cebad7 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-e9d1c8ee-f7cb-4f45-a9fd-dd13c9cebad7');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "  <div id=\"id_5fcc84f5-08fa-4a71-8863-1c51564dde0a\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_data')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_5fcc84f5-08fa-4a71-8863-1c51564dde0a button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('train_data');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                  query  \\\n",
       "0            SELECT count(*) FROM head WHERE age  >  56   \n",
       "1     SELECT name ,  born_state ,  age FROM head ORD...   \n",
       "2     SELECT creation ,  name ,  budget_in_billions ...   \n",
       "3     SELECT max(budget_in_billions) ,  min(budget_i...   \n",
       "4     SELECT avg(num_employees) FROM department WHER...   \n",
       "...                                                 ...   \n",
       "6995  SELECT T1.company_name FROM culture_company AS...   \n",
       "6996  SELECT T1.title ,  T3.book_title FROM movie AS...   \n",
       "6997  SELECT T1.title ,  T3.book_title FROM movie AS...   \n",
       "6998  SELECT T2.company_name FROM movie AS T1 JOIN c...   \n",
       "6999  SELECT T2.company_name FROM movie AS T1 JOIN c...   \n",
       "\n",
       "                                               question  \n",
       "0     How many heads of the departments are older th...  \n",
       "1     List the name, born state and age of the heads...  \n",
       "2     List the creation year, name and budget of eac...  \n",
       "3     What are the maximum and minimum budget of the...  \n",
       "4     What is the average number of employees of the...  \n",
       "...                                                 ...  \n",
       "6995  What are all the company names that have a boo...  \n",
       "6996  Show the movie titles and book titles for all ...  \n",
       "6997  What are the titles of movies and books corres...  \n",
       "6998  Show all company names with a movie directed i...  \n",
       "6999  What are all company names that have a corresp...  \n",
       "\n",
       "[7000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"query\", \"question\"]\n",
    "\n",
    "train_data = train_df[columns]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XL9itwo5MTpA"
   },
   "source": [
    "# 2. 4-bit base 모델 및 토크나이저 불러오기\n",
    "- 학습 목표 : 4-bit base 모델과 토크나이저를 불러올 수 있다.\n",
    "- 학습 개념 : 4-bit base 모델\n",
    "- 진행하는 실습 요약\n",
    "    - base 모델 불러오기\n",
    "    - 토크나이저 불러오기\n",
    "    - 양자화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osPVNyM3MTpA"
   },
   "source": [
    "사용할 모델은 [HuggingFaceTB/SmolLM2-1.7B-Instruct](https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B-Instruct)입니다.\n",
    "\n",
    "현재 6GB하의 VRAM에서 학습이 불가능한 모델입니다. 학습시 약 8GB의 VRAM이 필요합니다. 이 경우 QLoRA를 사용하여 학습을 진행할 수 있습니다. QLoRA로 학습을 진행하기 위해서는 모델을 4 bit로 초기화를 해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWa9svbdRD4m"
   },
   "source": [
    "모델 정밀도(model precisions)와 가장 일반적인 데이터 타입들(float16, float32, bfloat16, int8)에 대해 익숙하지 않다면 , 더 자세한 정보는 [컴퓨터의 소수점 표현](https://www.notion.so/ssunbell/2331806f5bc180f88c5dfe67eaf17738?source=copy_link)를 참고하시길 바랍니다.\n",
    "\n",
    "FP8(8-bit)과 FP4(4-bit)는 각각 부동 소수점 8비트와 4비트 정밀도를 의미합니다.\n",
    "\n",
    "먼저 FP8 형식으로 부동 소수점 값을 표현하는 방법을 살펴본 다음, FP4 형식이 어떻게 생겼는지 이해해 보겠습니다. FP8 형식 (FP8 format)은 부동 소수점은 n개의 비트로 구성되며 각 비트는 숫자의 구성 요소(부호, 가수, 지수)를 나타내는 특정 범주에 속합니다. 이들은 다음을 의미합니다.\n",
    "- FP8(부동 소수점 8) 형식은 \"딥러닝을 위한 FP8(FP8 for Deep Learning)\"이라는 논문에서 처음 소개되었으며, 두 가지 다른 FP8 인코딩 방식을 가집니다: E4M3 (지수 4비트, 가수 3비트)와 E5M2 (지수 5비트, 가수 2비트).\n",
    "\n",
    "<img src=\"./assets/img5.png\">\n",
    "\n",
    "- 비트 수를 32개에서 8개로 줄임으로써 정밀도가 상당히 감소하지만, 두 버전 모두 다양한 상황에서 사용될 수 있습니다.\n",
    "- E4M3 형식으로 표현할 수 있는 부동 소수점의 잠재적 범위는 -448에서 448 사이입니다.\n",
    "- E5M2 형식은 지수(exponent)의 비트 수가 늘어나면서 범위가 -57344에서 57344까지 늘어나지만, 표현 가능한 수의 총 개수는 일정하게 유지되므로 정밀도(precision)의 손실이 발생합니다.\n",
    "- 경험적으로 E4M3는 순전파(forward pass)에 가장 적합하고, 두 번째 버전(E5M2)은 역전파(backward computation)에 가장 적합하다는 것이 입증되었습니다\n",
    "\n",
    "\n",
    "FP4 정밀도 (FP4 precision in a few words)\n",
    "\n",
    "- 부호(sign) 비트는 부호(+/-)를 나타내고, 지수(exponent) 비트는 해당 비트로 표현된 정수의 2의 거듭제곱(예: $2^{010} = 2^2 = 4$)을 의미합니다.\n",
    "- 소수부(fraction) 또는 가수(mantissa)는 '1'로 되어 있는 각 비트에 대해 '활성화'되는 2의 음의 거듭제곱들의 합입니다.\n",
    "- 만약 비트가 '0'이면 해당 $2^{-i}$ (여기서 i는 비트 시퀀스 내의 위치)의 거듭제곱에 대해서는 소수부가 변경되지 않습니다.\n",
    "- 예를 들어, 가수 비트가 1010이라면 $(0 + 2^{-1} + 0 + 2^{-3}) = (0.5 + 0.125) = 0.625$가 됩니다.\n",
    "- 최종 값을 얻기 위해서는 소수부에 1을 더한 뒤 모든 결과를 곱합니다.\n",
    "- 예를 들어, 지수 비트 2개와 가수 비트 1개가 있을 때 '1101'이라는 표현은 다음과 같습니다:$$-1 * 2^2 * (1 + 2^{-1}) = -1 * 4 * 1.5 = -6$$\n",
    "- FP4에는 고정된 형식이 없으므로 다양한 가수/지수 조합을 시도해 볼 수 있습니다.\n",
    "- 일반적으로는 3개의 지수 비트를 사용하는 것이 대부분의 경우 더 좋은 성능을 보입니다. 하지만 때로는 2개의 지수 비트와 1개의 가수 비트를 사용하는 것이 더 나은 성능을 내기도 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYVIf7eNMTpA"
   },
   "source": [
    "4-bit(FP4) 모델을 불러오기 위해서는 먼저 `BitsAndBytesConfig`에서 4-bit에 대한 설정을 초기화해야 합니다.\n",
    "\n",
    "`BitsAndBytesConfig`는 `bitsandbytes`라고 하는 라이브러리의 config입니다. 양자화를 지원하는 라이브러리중에서 가장 간단하게 모델 양자화를 지원하고 있으며, 현재는 huggingface에서 `bitsandbytes` 관련된 설정도 지원하고 있으므로 저희는 huggingface에서 `bitsandbytes`를 설정하겠습니다.\n",
    "1. load_in_4bit=True\n",
    "- 설명: 모델의 가중치(weights)를 4비트 형식으로 로드하도록 활성화합니다.\n",
    "- 효과: 일반적으로 모델은 32비트(float32)나 16비트(float16/bfloat16)로 저장되는데, 이를 4비트로 줄여서 로드하므로 GPU 메모리(VRAM) 사용량을 획기적으로 줄여줍니다. (약 1/4 ~ 1/8 수준으로 감소)\n",
    "\n",
    "2. bnb_4bit_use_double_quant=True\n",
    "- 설명: 이중 양자화(Double Quantization) 기술을 적용합니다.\n",
    "- 상세: 양자화를 수행할 때 '양자화 상수(quantization constants)'라는 추가적인 파라미터가 생기는데, 이 상수들마저도 한 번 더 양자화하여 메모리를 절약하는 기법입니다.\n",
    "- 효과: 파라미터당 평균 약 0.4비트 정도의 추가적인 메모리 절약 효과가 있습니다. 성능 저하는 거의 없으면서 메모리를 극한으로 아끼고 싶을 때 사용합니다.\n",
    "\n",
    "3. bnb_4bit_quant_type=\"fp4\"\n",
    "- 설명: 4비트 데이터의 **형식(Data Type)**을 지정합니다.\n",
    "- 옵션:\n",
    "    - \"fp4\": 4-bit Float 형식입니다.\n",
    "    - \"nf4\": 4-bit NormalFloat 형식입니다. (참고: QLoRA 논문에서는 사전 학습된 신경망 가중치가 정규분포를 따르는 경향이 있으므로 \"nf4\"가 정보 손실이 더 적다고 제안합니다.)\n",
    "\n",
    "4. bnb_4bit_compute_dtype=torch.bfloat16\n",
    "- 설명: 실제 연산(Computation)을 수행할 때 사용할 데이터 타입을 지정합니다.\n",
    "- 상세: 가중치는 메모리 절약을 위해 4비트로 '저장'되어 있지만, 행렬 곱셈 같은 실제 연산을 할 때는 다시 4비트에서 실수형(float)으로 복원(Dequantize)해야 합니다. 이때 복원할 목표 타입을 bfloat16으로 설정한 것입니다.\n",
    "- 효과: float16보다 bfloat16이 표현 가능한 수의 범위(dynamic range)가 넓어 학습 안정성이 높기 때문에, Ampere 아키텍처 이상(예: A100, A10, RTX 30/40 시리즈 등)의 GPU를 사용한다면 bfloat16을 권장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "S-pMnq1yRD4m"
   },
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MezJdEPfRD4m"
   },
   "source": [
    "모델은 [HuggingFaceTB/SmolLM2-1.7B-Instruct](https://huggingface.co/naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B)를 사용하겠습니다. 이 모델은 스켈레톤 2에서 사용한 모델과 동일한 아키텍쳐이지만, 1.7B 모델 사이즈로 이전 0.36B 모델 사이즈보다 약 5배 더 큰 모델입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwNXd0QVRD4m"
   },
   "source": [
    "`quantization_config`를 추가하여 모델과 토크나이저를 load합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Os2e4oYuWbKX",
    "outputId": "b859ac28-3e30-4495-c04c-f074527ed5a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.49.2)\n",
      "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.10.0+cu128)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (26.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.3.0)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch<3,>=2.3->bitsandbytes) (1.3.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "044fded498ec4bcead698e9a6da8974d",
      "50715a964d754a918ae83ce42e67fb86",
      "491fba4d1de2420ba9814942895a445b",
      "83fd4d32b8e44477a1f7dd01bb542509",
      "2eeb00ca664148b58861ad209f7b9ef3",
      "5171ec61d115445fa747a7057351f8e1",
      "599a05b923a248c59199736d54eba52a",
      "29a9f4ba9d4b464d975e351fdc4fc71e",
      "8c1eb142280a424eaa80a50a7cf671a7",
      "5d4075e49a5146e6a8a0c0b111ede33b",
      "09f3104619644a5cb928529c956b27af",
      "f8d73361f8494980803b4753ce57cded",
      "35bec85303f349c3bb5c533dda215bc3",
      "74564b0783ae4a68acfab4ec95a19a8c",
      "1bcd4a36d6da4caa9de4bd887ee9756f",
      "a8441f5918aa41238d1f9806bec5d8e5",
      "e3ed14dc411245d7881e6f2eeaf094ff",
      "90ab95ef5fea460196506702c11c8631",
      "e6841f7227b3487ba98ee4523b6d23d8",
      "e069bd14baad44f5aba6caca5f2d4a8b",
      "48ddd55c3cfb4568b2af671bcfc26e23",
      "7381ebc661934b8f9d99222328236c49",
      "57fdf0bf266e4054922c36fde8b1cfab",
      "4273328d19d243c79041e9031ee92c39",
      "d8696f1ab58b40069809703930c29395",
      "af11b3c291a84efc9f203b3f4f34ea7a",
      "a952f9c01d03444c96111dcf4d9b1c16",
      "6adea437666c485bbf9391b082227f5e",
      "71aad6bc688043a69c831dd303a09c8d",
      "94917f9ba7e04d27b45fbe7a7235f714",
      "e5f370e096ad48e9a62babb4bbdbe9ac",
      "60b9065693644a918713667d686a5aa4",
      "3c843cd3d9ec4e5f8c4af54fcd94e97e",
      "2beeb9f426e840eb9b4c442a6c474aa3",
      "5f08d91933ac4b8d8565aaacb663d16b",
      "204803f7eda44d348c1726addcb1fd6b",
      "f06107d37d8643369cc87ece65ee16ed",
      "0d92915a464c44e9aad59b47b5f7b8f3",
      "790b5a9a3529470da9b5d118cb87edfd",
      "6ab78542fc1c44dca276e24136bbc10d",
      "a4838c4ddb2f4252b008390026e752a3",
      "949bd51bd1804c1a8b38d7336bed96b9",
      "73503c5b8af04bc3a5e76d1229bfdb9a",
      "b9472d5fbfdf4eda8820f3d5dbf9142a",
      "49d6e6daa3a2451982f4580bc38e2dfd",
      "135e724c58c246debb09335db3192adf",
      "8d285d4b02a744ee93dff79a7ddce753",
      "aec3a9b783b04959a31b8626510cf657",
      "606abf9dc002499fa82d132757d33ad7",
      "ede1aa1a04f14f75ab3912c158414994",
      "cc6be34c3bf546a79eb52ce4c0d10f04",
      "745337323b2241ce9a30e115a55a00eb",
      "c173c1b765a74af09b0152cba06a1d86",
      "2587ce3c328c4387ad73e3806e68e9b8",
      "c3628e99ee4e493daa5f16c89db11ec0",
      "bf245b3f121d4324a3c70a5813c1cb04",
      "7e4297650a2243848e8c539f6cbe634e",
      "a849dde45f5242f6af508085bba565cc",
      "c5739bc6e6fb4b2db368fbe1f6cd925f",
      "b5bd73b0c3af48f0999ff19ee5d15ceb",
      "6df14f969b83492684a789491fe28912",
      "150ad363a34d47fcbf397bc0100266d0",
      "1748d11529aa4b7d8f0d36a1d9f96c1e",
      "b87c049e6a3d4d77990872187d24350a",
      "c4ccd282069d4d0c95589b49cefb5b67",
      "924fe9bec1cd4c55a7b2573d4adbb71f",
      "2e3ce1f497cd4775b128587b628163ff",
      "efe22d32821a4958a28c2ba4bee9253e",
      "c26b27fab0dc47c6b6e852274724816f",
      "e9839cedbf8c4a698401202b5e0e6faf",
      "01364f75e7954b56a0dd550cdc2fddf7",
      "cd0c4c6a640142bc8ff0a10bb85922ea",
      "75519921c3a342ed96a21adb010cc3fb",
      "036dd3db9d8f440f93d8d28794b1513b",
      "777338b434d942edb0fbe2e26716aeac",
      "6fb8bbb4a17547ea8fe7d8d8b4c22c61",
      "1cdb36b9ca4d47e8852f92a3144f08d9"
     ]
    },
    "id": "7fxGvCckMTpA",
    "outputId": "cd40c781-c7ed-49c9-d883-0f967ed5d85f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044fded498ec4bcead698e9a6da8974d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/908 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d73361f8494980803b4753ce57cded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fdf0bf266e4054922c36fde8b1cfab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2beeb9f426e840eb9b4c442a6c474aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/655 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d6e6daa3a2451982f4580bc38e2dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf245b3f121d4324a3c70a5813c1cb04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3ce1f497cd4775b128587b628163ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"HuggingFaceTB/SmolLM2-1.7B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "if tokenizer.pad_token is None: # pad_token 설정이 되어있지 않는 경우가 존재합니다.\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map={\"\":\"cuda:0\"},\n",
    "    quantization_config=quantization_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xa0QhHUZRD4n"
   },
   "source": [
    "스켈레톤 2에서는 해당 모델을 불러올 때 메모리를 0.8GB를 차지했다면, 1.7B 모델을 4-bit로 양자화하여 불러온다면 메모리를 약 1.6GB로 차지할 것입니다.\n",
    "\n",
    "원래 1.7GB 모델을 불러오면 약 4GB를 차지하게 되고 4bit로 불러오면 4배가 줄어들게 되서 1GB가 되어야 할 것 같지만,\n",
    "\n",
    "모델의 성능 저하를 막기 위해서 Normalization Layers, softmax layer 등 특정 레이어는 4-bit로 만들지 않기 때문에 정확하게 4배가 줄어들지는 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vjHIz2kiRD4n",
    "outputId": "ed736a03-dd3a-4756-ef76-117e2c451900"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 24 02:05:08 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   55C    P0             29W /   70W |    3223MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A             882      C   /usr/bin/python3                       3220MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWnvZJVogocA"
   },
   "source": [
    "모델의 max_sequence_length를 확인합니다.\n",
    "\n",
    "max_position_embeddings의 길이는 position embeddings의 길이를 의미합니다.\n",
    "\n",
    "position embeddings는 입력 토큰에 순서 정보를 넣는 임베딩이므로 해당 차원이 실제 입력 토큰의 길이와 동일합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AMR9MTYDgocA",
    "outputId": "02d85e1d-2b8f-471c-a7a4-0617df8adf2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length of model: 8192\n",
      "Max sequence length: [251, 62, 0]\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length = model.config.max_position_embeddings\n",
    "max_sequence = [0, 0, 0]\n",
    "for i, row in train_data.iterrows():\n",
    "    for i, (k, v) in enumerate(row.items()):\n",
    "        max_sequence[i] = max(max_sequence[i], len(tokenizer(str(v))[\"input_ids\"]))\n",
    "\n",
    "print(\"Max sequence length of model:\", max_sequence_length)\n",
    "print(\"Max sequence length:\", max_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OENkJoTkgocB"
   },
   "source": [
    "8192의 길이라면 토크나이징을 한 이후의 `max_length`인 251 + 62 보다 훨씬 크기 때문에 충분히 여유롭습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8khDfofMTpB"
   },
   "source": [
    "# 3. Text-to-SQL task 데이터 전처리\n",
    "- 학습 목표 : chat 형식으로 데이터 전처리를 할 수 있다.\n",
    "- 학습 개념 : 데이터 전처리\n",
    "- 진행하는 실습 요약\n",
    "    - apply_chat_template으로 데이터 전처리하기\n",
    "    - datasets를 이용하여 Datasets 형식으로 변경하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ptz5jjWnMTpB"
   },
   "source": [
    "허깅페이스 tokenizer에서는 jinja2 포맷의 `chat_template`을 제공합니다.\n",
    "\n",
    "보통 LLM을 제공하는 회사, 모델마다 `chat_template`이 다릅니다. 또한, 최근에는 `chat_template`을 대부분 지원합니다.\n",
    "\n",
    "따라서, `chat_template`을 확인하고 `apply_chat_template` 매서드를 이용해서 어떻게 적용이 되는지 확인해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CvkxSQrZMTpB",
    "outputId": "80c12d78-ccbb-459d-f90e-7d11e91bf262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== chat template 사용 가능 ===\n",
      "\n",
      "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\n",
      "You are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n",
      "' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n"
     ]
    }
   ],
   "source": [
    "if tokenizer.chat_template:\n",
    "    print(\"=== chat template 사용 가능 ===\\n\")\n",
    "    print(tokenizer.chat_template)\n",
    "else:\n",
    "    print(\"=== chat template 사용 불가능 ===\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSjDuehkMTpB"
   },
   "source": [
    "Jinja2 포맷이 이상하긴 하지만 코드를 어느정도 이해하시는 분들이라면 이게 어떤 의미인지를 대충 유추해볼 수 있습니다.\n",
    "\n",
    "```jinja\n",
    "{% for message in messages %}\n",
    "```\n",
    "어떠한 `iterable` 객체를 `for loop`를 사용하는 것을 봐서는 `list` 등의 객체로 넣어줘야 할거 같습니다.\n",
    "\n",
    "\n",
    "```jinja\n",
    "{{'<|im_start|>' + message['role'] + '' + message['content'] + '<|im_end|>' + ''}}\n",
    "```\n",
    "\n",
    "`message` 내에 보면 `role`과 `content`라는 키값이 필요한 것을 알 수 있습니다. 여기서 `dictionary` 등의 객체를 사용하면 될거 같습니다.\n",
    "\n",
    "또한, 앞뒤에 `<|im_start|>`, `<|im_end|>`와 같은 스페셜 토큰이 붙는 것을 확인하실 수 있습니다. 이 부분은 저희가 건들 필요 없이 알아서 생성해줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2DRPXntMTpB"
   },
   "source": [
    "`apply_chat_template`의 입력으로 넣기 위해서는 chat(conversations) 형식을 지켜서 입력으로 넣어줘야 합니다.\n",
    "\n",
    "기존에 불러온 데이터프레임을 chat 형식으로 만들고 `apply_chat_template`을 적용해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dCUsJy-xMTpB",
    "outputId": "2c5ac321-fc1e-47d0-d608-2223a4c915b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'How many heads of the departments are older than 56 ?'}, {'role': 'assistant', 'content': 'SELECT count(*) FROM head WHERE age  >  56'}]\n",
      "\n",
      "<|im_start|>system\n",
      "You are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n",
      "<|im_start|>user\n",
      "How many heads of the departments are older than 56 ?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "SELECT count(*) FROM head WHERE age  >  56<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 학습용 데이터 전처리\n",
    "\n",
    "example = train_df[columns].iloc[0]\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": example[\"question\"]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": example[\"query\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(messages)\n",
    "print()\n",
    "chat = tokenizer.apply_chat_template(messages, tokenize = False, add_generation_prompt = False)\n",
    "print(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mik1sNt-MTpB"
   },
   "source": [
    "보시는 바와 같이 모델의 입력에 맞게 형식을 맞춰서 텍스트를 생성해주는 것을 확인하실 수 있습니다.\n",
    "\n",
    "주의할 점이 크게 2가지가 있습니다.\n",
    "1. `assistant`는 정답이기 때문에 학습에서만 입력으로 넣어주고 추론에서는 넣어줘서는 안됩니다.\n",
    "2. `add_generation_prompt=False`는 `assistant`가 들어갔기 때문에 `False`로 설정합니다. 추론용이라면 `True`로 설정해주셔야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gGhsfqgiMTpB",
    "outputId": "060da84d-1dab-4761-d6b9-b2ed4ae4d138"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n",
      "<|im_start|>user\n",
      "How many heads of the departments are older than 56 ?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 추론용 데이터 전처리\n",
    "chat_inference = tokenizer.apply_chat_template(messages[:-1], tokenize = False, add_generation_prompt = True)\n",
    "print(chat_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iImj1ZdsMTpB"
   },
   "source": [
    "추론용 데이터를 확인해보시면\n",
    "\n",
    "`SELECT count(*) FROM head WHERE age  >  56<|im_end|>`\n",
    "\n",
    "이 사라진 것을 확인하실 수 있습니다.\n",
    "\n",
    "유의할 점은\n",
    "1. 모델이 정답으로 생성할 텍스트 : `SELECT count(*) FROM head WHERE age  >  56`\n",
    "2. EOS 스페셜 토큰 : `<|im_end|>`\n",
    "\n",
    "두가지로 구성되어 있는 `assistant` 부분을 학습에 사용하게 됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lglZq-BNMTpC"
   },
   "source": [
    "이제 모델 입력으로 넣기 위해서 데이터를 전처리하도록 하겠습니다.\n",
    "\n",
    "데이터프레임에 있는 데이터를 꺼내서 `Dataset` 객체로 변환하는 전처리를 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ej6uwC7MTpC",
    "outputId": "09895a90-041c-4682-84dd-d64e123b0dcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are a text to SQL query translator. Users will ask you questions in English and you will generate a SQL query.', 'role': 'system'}, {'content': \"Given the <USER_QUERY>, generate the corresponding SQL command to retrieve the desired data, considering the query's syntax, semantics, and schema constraints.\\n\\n<USER_QUERY>\\nHow many heads of the departments are older than 56 ?\\n</USER_QUERY>\", 'role': 'user'}, {'content': 'SELECT count(*) FROM head WHERE age  >  56', 'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "system_prompt = \"\"\"You are a text to SQL query translator. Users will ask you questions in English and you will generate a SQL query.\"\"\"\n",
    "user_prompt = \"\"\"Given the <USER_QUERY>, generate the corresponding SQL command to retrieve the desired data, considering the query's syntax, semantics, and schema constraints.\n",
    "\n",
    "<USER_QUERY>\n",
    "{question}\n",
    "</USER_QUERY>\"\"\"\n",
    "\n",
    "def convert_to_conversation(examples):\n",
    "    train_data = []\n",
    "    for i in range(len(examples)):\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt.format(question=examples[\"question\"][i])\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": examples['query'][i]\n",
    "            }\n",
    "        ]\n",
    "        train_data.append(\n",
    "            {\n",
    "                \"messages\": messages,\n",
    "            }\n",
    "        )\n",
    "    return train_data\n",
    "\n",
    "train_data_list = convert_to_conversation(train_data)\n",
    "train_dataset = datasets.Dataset.from_list(train_data_list)\n",
    "print(train_dataset[\"messages\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DT4K6Y5yxuF5"
   },
   "source": [
    "보통 모델을 학습할 때 사용하는 labels는 inputs와 동일합니다.\n",
    "\n",
    "(모델은 내부적으로 labels를 한 칸 오른쪽으로 shift한 후 Cross-Entropy loss를 계산합니다. 이는 다음 토큰 예측(next token prediction)과 같은 auto-regressive 분류 작업에서 표준 방식입니다.)\n",
    "\n",
    "따라서 전처리된 샘플은 다음과 같은 형태가 됩니다:\n",
    "```python\n",
    "{\n",
    "    \"input_ids\": instruction + model response(assistant),\n",
    "    \"labels\": instruction + model response(assistant)\n",
    "}  # HF 모델이 shift +1 처리를 내부적으로 수행\n",
    "```\n",
    "\n",
    "- instruction : 모델에게 입력으로 넣을 지시사항 (실제 User들이 입력으로 넣을 텍스트)\n",
    "- model response : instruction에 대한 모델의 응답 (`assistant`와 동일)\n",
    "\n",
    "하지만 우리가 하려는 작업은 instruction 부분을 -100으로 대체하는 것입니다. 왜냐하면 저희는 모델이 정답(`assistant`) 부분만 학습을 하도록 하고 싶기 때문입니다.\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"input_ids\": instruction + model response(assistant),\n",
    "    \"labels\": [-100]*len(instruction) + model response(assistant)\n",
    "}\n",
    "```\n",
    "\n",
    "이렇게 하면 Cross-Entropy 함수에 instruction 토큰은 무시(ignore) 하라고 알려주는 셈입니다. 이를 통해 assistant 부분만 학습을 하도록 만들 수 있습니다.\n",
    "\n",
    "예를 들어,\n",
    "\n",
    "```\n",
    "<|im_start|>system\n",
    "You are a text to SQL query translator. Users will ask you questions in English and you will generate a SQL query.<|im_end|>\n",
    "<|im_start|>user\n",
    "Given the <USER_QUERY>, generate the corresponding SQL command to retrieve the desired data, considering the query's syntax, semantics, and schema constraints.\n",
    "\n",
    "<USER_QUERY>\n",
    "How many heads of the departments are older than 56 ?\n",
    "</USER_QUERY><|im_end|>\n",
    "<|im_start|>assistant\n",
    "SELECT count(*) FROM head WHERE age  >  56<|im_end|>\n",
    "```\n",
    "\n",
    "위에서 학습해야 할 부분(정답 라벨)은\n",
    "```\n",
    "SELECT count(*) FROM head WHERE age  >  56<|im_end|>\n",
    "```\n",
    "이 부분이므로, 나머지 부분들은 -100으로 마스킹 처리를 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aLOWwRq8wSwz",
    "outputId": "46eb3827-c86f-40a7-f454-8c931e768082"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✨ 데이터 변환 완벽 성공! 이제 훈련 가보자고! ✨\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def convert_train_data(examples, tokenizer):\n",
    "    messages = examples[\"messages\"]\n",
    "    label_message = messages[-1][\"content\"]\n",
    "    label_input_ids = tokenizer.encode(\n",
    "        label_message, add_special_tokens=False, return_tensors=\"pt\"\n",
    "    ).squeeze(0)\n",
    "\n",
    "    # 🚨 핵심 수정 부분: 스퀴즈(squeeze) 에러를 막아주는 방어막 전개!\n",
    "    prompt_output = tokenizer.apply_chat_template(\n",
    "        messages[:2], add_generation_prompt=False, tokenize=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    if isinstance(prompt_output, dict) or hasattr(prompt_output, \"input_ids\"):\n",
    "        prompt_input_ids = prompt_output[\"input_ids\"].squeeze(0)\n",
    "    else:\n",
    "        prompt_input_ids = prompt_output.squeeze(0)\n",
    "\n",
    "    response_start_template_ids = tokenizer.encode(\"<|im_start|>assistant\", return_tensors=\"pt\")[0]\n",
    "\n",
    "    input_ids = torch.cat(\n",
    "        [\n",
    "            prompt_input_ids,\n",
    "            response_start_template_ids,\n",
    "            label_input_ids,\n",
    "            torch.tensor([tokenizer.eos_token_id]),\n",
    "        ],\n",
    "        dim=0,\n",
    "    )\n",
    "    attention_mask = torch.ones(len(input_ids), dtype=torch.int64)\n",
    "    labels = torch.cat(\n",
    "        [\n",
    "            torch.tensor(\n",
    "                [-100] * (len(input_ids) - len(label_input_ids) - 1)\n",
    "            ),  # prompt + label_start_template\n",
    "            label_input_ids,  # label\n",
    "            torch.tensor([tokenizer.eos_token_id]),  # [EOS]\n",
    "        ],\n",
    "        dim=0,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "datasets.disable_progress_bar()\n",
    "train_dataset = train_dataset.map(\n",
    "    lambda x: convert_train_data(x, tokenizer),\n",
    "    batched=False,\n",
    "    num_proc=1,\n",
    "    remove_columns=train_dataset.column_names  # 원본 컬럼 제거하고 새 컬럼만 남김\n",
    ")\n",
    "\n",
    "# 🚨 잘려있던 꼬리 복구: 데이터를 텐서 블록으로 확실하게 변환!\n",
    "train_dataset.set_format(type=\"torch\")\n",
    "print(\"✨ 데이터 변환 완벽 성공! 이제 훈련 가보자고! ✨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWTQ8p6T0Kx8"
   },
   "source": [
    "1. input_ids – 토크나이즈된 시퀀스 데이터\n",
    "- 토크나이저(tokenizer)가 텍스트를 **서브워드 단위(subword units)**로 분할하고, 이를 **어휘 사전(vocabulary)**에 정의된 **토큰 인덱스(token index)**로 변환합니다.\n",
    "- 이 시퀀스가 Transformer 모델의 **임베딩 레이어(embedding layer)**에 입력되어, 각 정수가 고차원 벡터로 임베딩됩니다.\n",
    "\n",
    "2. attention_mask – 시퀀스 마스킹 텐서\n",
    "- Transformer는 일반적으로 고정된 최대 길이(max sequence length) 입력을 사용합니다.\n",
    "- 실제 입력 길이가 짧으면 패딩(padding)을 추가해 맞추는데, 이때 패딩 토큰은 self-attention 연산에서 무시되어야 합니다.\n",
    "- attention_mask는 같은 길이의 바이너리 벡터로,\n",
    "  - 실제 토큰 위치 → 1\n",
    "  - 패딩 토큰 위치 → 0\n",
    "- 이 마스크는 어텐션 스코어(attention score) 계산 시 소프트맥스 이전에 매우 작은 음수(−∞)를 더해, 패딩 위치의 기여도를 완전히 제거합니다.\n",
    "\n",
    "3. labels – 학습 대상(target) 시퀀스\n",
    "- labels는 **모델의 출력 로짓(logits)**과 비교할 타겟 시퀀스입니다.\n",
    "- 언어 모델 학습 시 auto-regressive(next-token prediction) 방식으로 학습하므로, labels는 보통 input_ids와 동일하지만 손실 계산에서 제외할 토큰 위치를 -100으로 마스킹합니다.\n",
    "- 이렇게 하면 Cross-Entropy Loss 계산 시 무시된 위치는 loss=0으로 처리됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qx9Ai-ynz63S",
    "outputId": "c54a96d8-6197-4588-8ffe-6abc16a1b499"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids :  tensor([    1,  9690,   198,  2683,   359,   253,  1694,   288, 15142,  8520,\n",
      "        31077,    30, 21626,   523,  1998,   346,  2029,   281,  2321,   284,\n",
      "          346,   523,  5051,   253, 15142,  8520,    30,     2,   198,     1,\n",
      "         4093,   198, 15423,   260,  2067, 23824,    79, 11745, 33642, 18128,\n",
      "         5051,   260,  8030, 15142,  3588,   288, 19662,   260,  6253,   940,\n",
      "           28,  6361,   260,  8520,   506, 17227,    28, 35243,    28,   284,\n",
      "        17808, 10195,    30,   198,   198,    44, 23824,    79, 11745, 33642,\n",
      "           46,   198,  2020,   800,  8648,   282,   260, 11609,   359,  3943,\n",
      "          670,   216,    37,    38,  9148,   198,  9617, 23824,    79, 11745,\n",
      "        33642,    46,     2,   198,     1,   520,  9531, 23428,   985, 12905,\n",
      "           25, 18451,  1680, 28531,  1850,   216,  2986,   256,    37,    38,\n",
      "            2])\n",
      "attention_mask :  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "labels :  tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100, 23428,   985, 12905,\n",
      "           25, 18451,  1680, 28531,  1850,   216,  2986,   256,    37,    38,\n",
      "            2])\n"
     ]
    }
   ],
   "source": [
    "print(\"input_ids : \", train_dataset[\"input_ids\"][0])\n",
    "print(\"attention_mask : \", train_dataset[\"attention_mask\"][0])\n",
    "print(\"labels : \", train_dataset[\"labels\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_qVhhdsRD4w"
   },
   "source": [
    "# 4. base model 성능 측정\n",
    "- 학습 목표 : spider 벤치마크를 이용해서 base model의 성능을 측정할 수 있다.\n",
    "- 학습 개념 : metric\n",
    "- 진행하는 실습 요약\n",
    "    - 테스트 데이터셋 불러오기\n",
    "    - 성능 측정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-3cKx5aRD4w"
   },
   "source": [
    "model 학습을 하기 전에 base model의 성능이 얼마인지를 측정합니다.\n",
    "\n",
    "모델의 성능을 측정하기 위해서는 2가지가 필요합니다.\n",
    "1. 성능을 측정하기 위한 테스트 데이터셋\n",
    "2. 성능을 측정하기 위한 지표\n",
    "\n",
    "spider 데이터셋에 있는 test 데이터셋을 활용하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chql2qekRD4w"
   },
   "source": [
    "학습 데이터셋과 동일한 성격을 가진 데이터셋입니다.\n",
    "\n",
    "따라서, 테스트 데이터셋도 동일하게 필요한 column만 남기도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8fINiWlrRD4w",
    "outputId": "c29ff228-0205-4ccc-a0aa-f744b953a935"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"test_data\",\n  \"rows\": 60,\n  \"fields\": [\n    {\n      \"column\": \"query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"SELECT Name ,  Birth_Date FROM people ORDER BY Name ASC\",\n          \"SELECT count(DISTINCT country_code) FROM players\",\n          \"SELECT template_id ,  version_number ,  template_type_code FROM Templates\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 60,\n        \"samples\": [\n          \"What are all distinct countries where singers above age 20 are from?\",\n          \"How many different types of pet are there?\",\n          \"How many transcripts are released?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "test_data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-1e5827c1-68c0-435f-8e46-8055939b2d84\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SELECT DISTINCT country FROM singer WHERE age ...</td>\n",
       "      <td>What are all distinct countries where singers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SELECT DISTINCT country FROM singer WHERE age ...</td>\n",
       "      <td>What are  the different countries with singers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SELECT count(*) FROM pets WHERE weight  &gt;  10</td>\n",
       "      <td>Find the number of pets whose weight is heavie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SELECT count(*) FROM pets WHERE weight  &gt;  10</td>\n",
       "      <td>How many pets have a greater weight than 10?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SELECT count(DISTINCT pettype) FROM pets</td>\n",
       "      <td>Find the number of distinct type of pets.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SELECT count(DISTINCT pettype) FROM pets</td>\n",
       "      <td>How many different types of pet are there?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SELECT count(*) FROM CONTINENTS;</td>\n",
       "      <td>How many continents are there?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SELECT count(*) FROM CONTINENTS;</td>\n",
       "      <td>What is the number of continents?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SELECT count(*) FROM AIRLINES</td>\n",
       "      <td>How many airlines do we have?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SELECT count(*) FROM AIRLINES</td>\n",
       "      <td>What is the total number of airlines?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SELECT count(*) FROM AIRPORTS</td>\n",
       "      <td>How many airports do we have?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SELECT count(*) FROM AIRPORTS</td>\n",
       "      <td>Return the number of  airports.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SELECT count(*) FROM AIRLINES WHERE Country  =...</td>\n",
       "      <td>How many airlines are from USA?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SELECT count(*) FROM AIRLINES WHERE Country  =...</td>\n",
       "      <td>Return the number of airlines in the USA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SELECT count(*) FROM Documents</td>\n",
       "      <td>How many documents do we have?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SELECT count(*) FROM Documents</td>\n",
       "      <td>Count the number of documents.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SELECT count(*) FROM Templates</td>\n",
       "      <td>How many templates do we have?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SELECT count(*) FROM Templates</td>\n",
       "      <td>Count the number of templates.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SELECT DISTINCT template_type_code FROM Templates</td>\n",
       "      <td>Show all distinct template type codes for all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SELECT DISTINCT template_type_code FROM Templates</td>\n",
       "      <td>What are the different template type codes?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SELECT count(*) FROM Templates WHERE template_...</td>\n",
       "      <td>How many templates have template type code CV?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SELECT count(*) FROM Templates WHERE template_...</td>\n",
       "      <td>Count the number of templates of the type CV.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SELECT count(*) FROM Paragraphs</td>\n",
       "      <td>How many paragraphs in total?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SELECT count(*) FROM Paragraphs</td>\n",
       "      <td>Count the number of paragraphs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SELECT Name FROM teacher ORDER BY Age ASC</td>\n",
       "      <td>List the names of teachers in ascending order ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SELECT Name FROM teacher ORDER BY Age ASC</td>\n",
       "      <td>What are the names of the teachers ordered by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SELECT count(*) FROM players</td>\n",
       "      <td>Find the total number of players.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SELECT count(*) FROM players</td>\n",
       "      <td>How many players are there?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SELECT count(*) FROM matches</td>\n",
       "      <td>Find the total number of matches.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SELECT count(*) FROM matches</td>\n",
       "      <td>Count the number of matches.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SELECT count(DISTINCT country_code) FROM players</td>\n",
       "      <td>find the number of distinct country codes of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SELECT count(DISTINCT country_code) FROM players</td>\n",
       "      <td>How many distinct countries do players come from?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SELECT count(*) FROM Courses</td>\n",
       "      <td>How many courses in total are listed?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SELECT count(*) FROM Courses</td>\n",
       "      <td>How many courses are there?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SELECT avg(transcript_date) FROM Transcripts</td>\n",
       "      <td>On average, when were the transcripts printed?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SELECT avg(transcript_date) FROM Transcripts</td>\n",
       "      <td>What is the average transcript date?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SELECT count(*) FROM Transcripts</td>\n",
       "      <td>How many transcripts are released?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SELECT count(*) FROM Transcripts</td>\n",
       "      <td>How many transcripts are listed?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SELECT count(*) FROM TV_Channel WHERE LANGUAGE...</td>\n",
       "      <td>How many TV Channel using language English?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SELECT count(*) FROM TV_Channel WHERE LANGUAGE...</td>\n",
       "      <td>How many TV Channels use the English language?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SELECT Name FROM conductor ORDER BY Age ASC</td>\n",
       "      <td>List the names of conductors in ascending orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SELECT Name FROM conductor ORDER BY Age ASC</td>\n",
       "      <td>What are the names of conductors, ordered by age?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SELECT avg(age) FROM Dogs</td>\n",
       "      <td>What is the average age of all the dogs?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>SELECT avg(age) FROM Dogs</td>\n",
       "      <td>Compute the average age of all the dogs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>SELECT template_id ,  count(*) FROM Documents ...</td>\n",
       "      <td>Show all template ids and number of documents ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>SELECT template_id ,  count(*) FROM Documents ...</td>\n",
       "      <td>What are all different template ids used for d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>SELECT template_id ,  version_number ,  templa...</td>\n",
       "      <td>Show template ids, version numbers, and templa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SELECT template_id ,  version_number ,  templa...</td>\n",
       "      <td>What are the ids, version numbers, and type co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SELECT count(*) FROM matches WHERE YEAR  =  20...</td>\n",
       "      <td>List the number of all matches who played in y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>SELECT count(*) FROM matches WHERE YEAR  =  20...</td>\n",
       "      <td>How many matches were played in 2013 or 2016?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>SELECT max(SHARE) , min(SHARE) FROM TV_series;</td>\n",
       "      <td>What is minimum and maximum share of TV series?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>SELECT max(SHARE) , min(SHARE) FROM TV_series;</td>\n",
       "      <td>What is the maximum and minimum share for the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>SELECT Nationality ,  COUNT(*) FROM people GRO...</td>\n",
       "      <td>What are different nationalities of people and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SELECT Nationality ,  COUNT(*) FROM people GRO...</td>\n",
       "      <td>How many people are there of each nationality?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>SELECT Name ,  Birth_Date FROM people ORDER BY...</td>\n",
       "      <td>List the names and birth dates of people in as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>SELECT Name ,  Birth_Date FROM people ORDER BY...</td>\n",
       "      <td>What are the names and birth dates of people, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>SELECT max(SHARE) ,  min(SHARE) FROM performan...</td>\n",
       "      <td>What are the maximum and minimum share of perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>SELECT max(SHARE) ,  min(SHARE) FROM performan...</td>\n",
       "      <td>Return the maximum and minimum shares for perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>SELECT student_id ,  count(*) FROM Likes GROUP...</td>\n",
       "      <td>Count the number of likes for each student id.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>SELECT student_id ,  count(*) FROM Likes GROUP...</td>\n",
       "      <td>How many likes correspond to each student id?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e5827c1-68c0-435f-8e46-8055939b2d84')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-1e5827c1-68c0-435f-8e46-8055939b2d84 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-1e5827c1-68c0-435f-8e46-8055939b2d84');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "  <div id=\"id_c1794f34-76ad-4a97-aed9-4c52fe9ee230\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_data')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_c1794f34-76ad-4a97-aed9-4c52fe9ee230 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('test_data');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                query  \\\n",
       "0   SELECT DISTINCT country FROM singer WHERE age ...   \n",
       "1   SELECT DISTINCT country FROM singer WHERE age ...   \n",
       "2       SELECT count(*) FROM pets WHERE weight  >  10   \n",
       "3       SELECT count(*) FROM pets WHERE weight  >  10   \n",
       "4            SELECT count(DISTINCT pettype) FROM pets   \n",
       "5            SELECT count(DISTINCT pettype) FROM pets   \n",
       "6                    SELECT count(*) FROM CONTINENTS;   \n",
       "7                    SELECT count(*) FROM CONTINENTS;   \n",
       "8                       SELECT count(*) FROM AIRLINES   \n",
       "9                       SELECT count(*) FROM AIRLINES   \n",
       "10                      SELECT count(*) FROM AIRPORTS   \n",
       "11                      SELECT count(*) FROM AIRPORTS   \n",
       "12  SELECT count(*) FROM AIRLINES WHERE Country  =...   \n",
       "13  SELECT count(*) FROM AIRLINES WHERE Country  =...   \n",
       "14                     SELECT count(*) FROM Documents   \n",
       "15                     SELECT count(*) FROM Documents   \n",
       "16                     SELECT count(*) FROM Templates   \n",
       "17                     SELECT count(*) FROM Templates   \n",
       "18  SELECT DISTINCT template_type_code FROM Templates   \n",
       "19  SELECT DISTINCT template_type_code FROM Templates   \n",
       "20  SELECT count(*) FROM Templates WHERE template_...   \n",
       "21  SELECT count(*) FROM Templates WHERE template_...   \n",
       "22                    SELECT count(*) FROM Paragraphs   \n",
       "23                    SELECT count(*) FROM Paragraphs   \n",
       "24          SELECT Name FROM teacher ORDER BY Age ASC   \n",
       "25          SELECT Name FROM teacher ORDER BY Age ASC   \n",
       "26                       SELECT count(*) FROM players   \n",
       "27                       SELECT count(*) FROM players   \n",
       "28                       SELECT count(*) FROM matches   \n",
       "29                       SELECT count(*) FROM matches   \n",
       "30   SELECT count(DISTINCT country_code) FROM players   \n",
       "31   SELECT count(DISTINCT country_code) FROM players   \n",
       "32                       SELECT count(*) FROM Courses   \n",
       "33                       SELECT count(*) FROM Courses   \n",
       "34       SELECT avg(transcript_date) FROM Transcripts   \n",
       "35       SELECT avg(transcript_date) FROM Transcripts   \n",
       "36                   SELECT count(*) FROM Transcripts   \n",
       "37                   SELECT count(*) FROM Transcripts   \n",
       "38  SELECT count(*) FROM TV_Channel WHERE LANGUAGE...   \n",
       "39  SELECT count(*) FROM TV_Channel WHERE LANGUAGE...   \n",
       "40        SELECT Name FROM conductor ORDER BY Age ASC   \n",
       "41        SELECT Name FROM conductor ORDER BY Age ASC   \n",
       "42                          SELECT avg(age) FROM Dogs   \n",
       "43                          SELECT avg(age) FROM Dogs   \n",
       "44  SELECT template_id ,  count(*) FROM Documents ...   \n",
       "45  SELECT template_id ,  count(*) FROM Documents ...   \n",
       "46  SELECT template_id ,  version_number ,  templa...   \n",
       "47  SELECT template_id ,  version_number ,  templa...   \n",
       "48  SELECT count(*) FROM matches WHERE YEAR  =  20...   \n",
       "49  SELECT count(*) FROM matches WHERE YEAR  =  20...   \n",
       "50     SELECT max(SHARE) , min(SHARE) FROM TV_series;   \n",
       "51     SELECT max(SHARE) , min(SHARE) FROM TV_series;   \n",
       "52  SELECT Nationality ,  COUNT(*) FROM people GRO...   \n",
       "53  SELECT Nationality ,  COUNT(*) FROM people GRO...   \n",
       "54  SELECT Name ,  Birth_Date FROM people ORDER BY...   \n",
       "55  SELECT Name ,  Birth_Date FROM people ORDER BY...   \n",
       "56  SELECT max(SHARE) ,  min(SHARE) FROM performan...   \n",
       "57  SELECT max(SHARE) ,  min(SHARE) FROM performan...   \n",
       "58  SELECT student_id ,  count(*) FROM Likes GROUP...   \n",
       "59  SELECT student_id ,  count(*) FROM Likes GROUP...   \n",
       "\n",
       "                                             question  \n",
       "0   What are all distinct countries where singers ...  \n",
       "1   What are  the different countries with singers...  \n",
       "2   Find the number of pets whose weight is heavie...  \n",
       "3        How many pets have a greater weight than 10?  \n",
       "4           Find the number of distinct type of pets.  \n",
       "5          How many different types of pet are there?  \n",
       "6                      How many continents are there?  \n",
       "7                   What is the number of continents?  \n",
       "8                       How many airlines do we have?  \n",
       "9               What is the total number of airlines?  \n",
       "10                      How many airports do we have?  \n",
       "11                    Return the number of  airports.  \n",
       "12                    How many airlines are from USA?  \n",
       "13          Return the number of airlines in the USA.  \n",
       "14                     How many documents do we have?  \n",
       "15                     Count the number of documents.  \n",
       "16                     How many templates do we have?  \n",
       "17                     Count the number of templates.  \n",
       "18  Show all distinct template type codes for all ...  \n",
       "19        What are the different template type codes?  \n",
       "20     How many templates have template type code CV?  \n",
       "21      Count the number of templates of the type CV.  \n",
       "22                      How many paragraphs in total?  \n",
       "23                    Count the number of paragraphs.  \n",
       "24  List the names of teachers in ascending order ...  \n",
       "25  What are the names of the teachers ordered by ...  \n",
       "26                  Find the total number of players.  \n",
       "27                        How many players are there?  \n",
       "28                  Find the total number of matches.  \n",
       "29                       Count the number of matches.  \n",
       "30  find the number of distinct country codes of a...  \n",
       "31  How many distinct countries do players come from?  \n",
       "32              How many courses in total are listed?  \n",
       "33                        How many courses are there?  \n",
       "34     On average, when were the transcripts printed?  \n",
       "35               What is the average transcript date?  \n",
       "36                 How many transcripts are released?  \n",
       "37                   How many transcripts are listed?  \n",
       "38        How many TV Channel using language English?  \n",
       "39     How many TV Channels use the English language?  \n",
       "40  List the names of conductors in ascending orde...  \n",
       "41  What are the names of conductors, ordered by age?  \n",
       "42           What is the average age of all the dogs?  \n",
       "43           Compute the average age of all the dogs.  \n",
       "44  Show all template ids and number of documents ...  \n",
       "45  What are all different template ids used for d...  \n",
       "46  Show template ids, version numbers, and templa...  \n",
       "47  What are the ids, version numbers, and type co...  \n",
       "48  List the number of all matches who played in y...  \n",
       "49      How many matches were played in 2013 or 2016?  \n",
       "50    What is minimum and maximum share of TV series?  \n",
       "51  What is the maximum and minimum share for the ...  \n",
       "52  What are different nationalities of people and...  \n",
       "53     How many people are there of each nationality?  \n",
       "54  List the names and birth dates of people in as...  \n",
       "55  What are the names and birth dates of people, ...  \n",
       "56  What are the maximum and minimum share of perf...  \n",
       "57  Return the maximum and minimum shares for perf...  \n",
       "58     Count the number of likes for each student id.  \n",
       "59      How many likes correspond to each student id?  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = text_to_sql[\"test\"].to_pandas()\n",
    "test_data = test_df[columns]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68uibEM9RD4w",
    "outputId": "a5217211-7688-4ba9-c0e0-63cab1a0b7e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답 : SELECT DISTINCT country FROM singer WHERE age  >  20\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "\n",
    "test_input = [\n",
    "    {'role': 'system', 'content': system_prompt},\n",
    "    {'role': 'user', 'content': user_prompt.format(question=test_data[\"question\"][text_idx])},\n",
    "]\n",
    "print(\"정답 :\", test_data[\"query\"][text_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4I7C9DYRD4w"
   },
   "source": [
    "이제 base model의 성능을 측정하기 위해 측정 metric을 설정합니다. 저희가 사용할 metric은 `execution accuracy`입니다.\n",
    "\n",
    "text to sql task의 경우, 자연어를 입력으로 받아 model이 sql문을 출력하는 것이므로, 모델의 response 결과물이 실제 sql문이 잘 동작하는지를 기준으로 평가를 진행할 수 있습니다. 이러한 평가 방식은 sql문은 다르더라도 의도대로 실행이 되었다면 정답이 될 수 있으므로 정확히 SQL문이 일치하는지 평가하는 exact match 보다 유연한 방식입니다.\n",
    "\n",
    "이러한 metric은 실제로 database에 들어있는 데이터를 sql문을 실행했을 때, 의도한 sql문이 동작하는지를 평가하는 방식입니다. 아래 예시 데이터로 진행해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgj4y2LQRD4w"
   },
   "source": [
    "다음은 평가 프로세스 상세 흐름입니다.\n",
    "\n",
    "**Step 1: 파일 준비 및 읽기**\n",
    "\n",
    "평가를 시작하기 위해 두 개의 텍스트 파일을 준비합니다.\n",
    "\n",
    "**1-1. 정답 파일(Gold) 읽기**\n",
    "- 시험지의 정답지와 같은 역할을 합니다\n",
    "- 각 줄에는 \"정답 SQL 쿼리\"와 \"어떤 데이터베이스를 사용할지\"가 탭으로 구분되어 있습니다\n",
    "- 빈 줄이 나오면 하나의 대화 세션이 끝났다는 의미입니다\n",
    "- 결과: 여러 세션의 정답들이 리스트로 정리됩니다\n",
    "\n",
    "**1-2. 예측 파일(Predict) 읽기**\n",
    "- 학생이 제출한 답안지와 같은 역할입니다\n",
    "- 각 줄에는 모델이 생성한 SQL 쿼리가 들어있습니다\n",
    "- 마찬가지로 빈 줄로 세션을 구분합니다\n",
    "- 결과: 모델의 예측들이 리스트로 정리됩니다\n",
    "\n",
    "**1-3. 개수 확인**\n",
    "- 정답과 예측의 개수가 정확히 일치하는지 확인합니다\n",
    "- 만약 개수가 다르면 평가를 진행할 수 없으므로 오류가 발생합니다\n",
    "\n",
    "**Step 2: 평가 준비 작업**\n",
    "\n",
    "**2-1. 평가 도구 준비**\n",
    "- Evaluator라는 채점 도구를 준비합니다\n",
    "- 이 도구가 SQL을 분석하고 점수를 계산합니다\n",
    "\n",
    "**2-2. 점수판 초기화**\n",
    "- 난이도별 점수판을 만듭니다 (쉬움, 보통, 전체)\n",
    "- 각 점수판에는 다음 정보를 담을 공간을 마련합니다:\n",
    "  - 문제 개수\n",
    "  - 실행 정확도 (실제로 돌려봤을 때 맞는지)\n",
    "  - 구조 정확도 (SQL 문법 구조가 맞는지)\n",
    "  - 부분 점수 (SELECT, WHERE 등 각 부분별 점수)\n",
    "\n",
    "**Step 3: 본격적인 채점 시작**\n",
    "\n",
    "모든 SQL 쿼리 쌍(정답과 예측)에 대해 하나씩 채점을 진행합니다.\n",
    "\n",
    "**Step 3-1: SQL 이해하기 (파싱)**\n",
    "\n",
    "**정답 SQL 분석**\n",
    "- 데이터베이스의 구조 정보(스키마)를 먼저 불러옵니다\n",
    "  - 어떤 테이블이 있는지\n",
    "  - 각 테이블에 어떤 컬럼이 있는지\n",
    "  - 테이블 간 관계(외래키)가 어떻게 되는지\n",
    "\n",
    "- 정답 SQL 문자열을 컴퓨터가 이해할 수 있는 구조화된 형태로 변환합니다\n",
    "  - 예: \"SELECT name FROM students WHERE age > 20\"\n",
    "  - 이것을 → SELECT 부분은 무엇, FROM 부분은 무엇, WHERE 조건은 무엇... 이렇게 분해합니다\n",
    "\n",
    "**예측 SQL 분석**\n",
    "- 모델이 생성한 SQL도 같은 방식으로 분석합니다\n",
    "- 만약 SQL 문법이 잘못되어 분석이 불가능하면, 빈 SQL로 간주합니다 (0점 처리)\n",
    "\n",
    "**Step 3-2: 난이도 판정**\n",
    "\n",
    "정답 SQL을 보고 이 문제가 얼마나 어려운지 자동으로 판단합니다.\n",
    "\n",
    "**난이도 계산 기준**\n",
    "- **기본 요소 카운트**: WHERE, GROUP BY, ORDER BY, LIMIT, JOIN, OR, LIKE 같은 것들이 몇 개 있는지\n",
    "- **복잡도 카운트**: 서브쿼리(중첩 쿼리)가 있는지, UNION/INTERSECT/EXCEPT가 있는지\n",
    "- **추가 요소 카운트**: 집계함수를 여러 번 쓰는지, SELECT에 여러 컬럼이 있는지 등\n",
    "\n",
    "**난이도 등급**\n",
    "- **쉬움(easy)**: 기본적인 SELECT와 간단한 조건 하나 정도\n",
    "- **보통(medium)**: 조건이 2~3개 있거나 JOIN이 하나 정도 있는 수준\n",
    "\n",
    "**Step 3-3: 실행 결과로 채점 (Execution 평가)**\n",
    "\n",
    "실제로 SQL을 데이터베이스에서 실행해서 결과가 같은지 확인합니다.\n",
    "\n",
    "**실행 평가 과정**\n",
    "1. 정답 SQL을 실행해서 결과 테이블 A를 얻습니다\n",
    "2. 예측 SQL을 실행해서 결과 테이블 B를 얻습니다\n",
    "3. 여러 개의 테스트 데이터베이스에서 반복 실행합니다\n",
    "   - 왜냐하면 우연히 하나의 데이터베이스에서만 맞을 수도 있으니까요\n",
    "4. 모든 테스트에서 A와 B가 완전히 동일하면 정답\n",
    "5. 하나라도 다르면 오답\n",
    "\n",
    "**점수 기록**\n",
    "- 맞으면 해당 난이도, 해당 턴, 전체 점수에 1점 추가\n",
    "- 틀리면 0점\n",
    "\n",
    "**Step 3-4: 구조로 채점 (Exact Match 평가)**\n",
    "\n",
    "SQL의 구조가 정답과 정확히 같은지 세밀하게 비교합니다.\n",
    "\n",
    "**전처리 작업**\n",
    "- 값(Value)을 무시하도록 설정합니다\n",
    "  - 예: \"age > 20\"과 \"age > 30\"을 같은 구조로 봅니다 (숫자는 달라도 됨)\n",
    "- 외래키 관계를 고려해서 컬럼을 정리합니다\n",
    "  - 예: `students.dept_id`와 `departments.id`가 같은 것을 의미할 수 있음\n",
    "\n",
    "**각 부분별 상세 채점**\n",
    "\n",
    "1. **SELECT 절 채점**\n",
    "   - 선택한 컬럼들이 정답과 같은지 확인\n",
    "   - 집계함수(COUNT, SUM, AVG 등) 사용이 맞는지 확인\n",
    "   - 순서는 상관없이 내용만 비교\n",
    "\n",
    "2. **WHERE 절 채점**\n",
    "   - 조건들이 정답과 같은지 확인\n",
    "   - 비교 연산자(=, >, <, LIKE 등)가 맞는지 확인\n",
    "   - 여러 조건이 있으면 하나씩 체크\n",
    "\n",
    "3. **GROUP BY 절 채점**\n",
    "   - 그룹핑하는 컬럼이 맞는지 확인\n",
    "   - 테이블명은 무시하고 컬럼명만 비교\n",
    "\n",
    "4. **ORDER BY 절 채점**\n",
    "   - 정렬 기준 컬럼이 맞는지 확인\n",
    "   - 오름차순/내림차순이 맞는지 확인\n",
    "   - LIMIT과 함께 사용되었는지도 체크\n",
    "\n",
    "5. **JOIN 채점**\n",
    "   - 어떤 테이블들을 연결했는지 확인\n",
    "   - 연결 조건이 맞는지 확인\n",
    "\n",
    "6. **AND/OR 채점**\n",
    "   - 조건들을 연결하는 방식이 맞는지 확인\n",
    "\n",
    "7. **서브쿼리 채점**\n",
    "   - UNION, INTERSECT, EXCEPT 같은 복잡한 쿼리가 맞는지 확인\n",
    "   - 서브쿼리 내부도 재귀적으로 같은 방식으로 채점\n",
    "\n",
    "**최종 판정**\n",
    "- 모든 부분이 100% 일치하면 Exact Match 성공 (1점)\n",
    "- 하나라도 다르면 실패 (0점)\n",
    "- 각 부분별 점수도 따로 기록 (부분 점수)\n",
    "\n",
    "**Step 4: 결과 정리 및 출력**\n",
    "\n",
    "모든 쿼리에 대한 채점이 끝나면 최종 점수를 계산합니다.\n",
    "\n",
    "**4-1. 평균 계산**\n",
    "- 각 난이도별로 정확도를 계산합니다\n",
    "  - 예: 쉬운 문제 100개 중 85개 맞음 → 85% 정확도\n",
    "- 실행 정확도와 구조 정확도를 각각 계산합니다\n",
    "- 부분 점수도 계산합니다\n",
    "  - Accuracy(정확도): 예측한 것 중 맞은 비율\n",
    "  - Recall(재현율): 정답에 있는 것 중 찾은 비율\n",
    "  - F1 점수: Accuracy와 Recall의 조화평균\n",
    "\n",
    "**4-2. 결과 출력**\n",
    "화면에 보기 좋게 표 형태로 결과를 출력합니다:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gA-mqUr-RD4w",
    "outputId": "46bb1cba-8202-4435-b6da-315334d0d1cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: powershell: command not found\n"
     ]
    }
   ],
   "source": [
    "# Powershell\n",
    "!powershell \"cd test-suite-sql-eval-master ; python evaluation.py --gold gold.txt --pred base_model_predict.txt --db database/ --etype exec --plug_value\"\n",
    "# git bash\n",
    "# !cd test-suite-sql-eval-master && python evaluation.py --gold gold.txt --pred base_model_predict.txt --db database/ --etype exec --plug_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwrVPUnyMTpC"
   },
   "source": [
    "# 5. Text-to-SQL task 모델 QLoRA fine-tuning\n",
    "- 학습 목표 : text-to-sql task에 대한 QLoRA fine-tuning을 진행할 수 있다.\n",
    "- 학습 개념 : QLoRA, Trainer\n",
    "- 진행하는 실습 요약\n",
    "    - QLoRA fine-tuning\n",
    "    - 성능 측정\n",
    "\n",
    "QLoRA 설정과 Trainer 설정을 하고 모델 학습을 진행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hL-teOqmMTpC"
   },
   "source": [
    "QLoRA는 Quantization 모델에 LoRA 학습을 진행하는 것이므로 LoRA 설정을 그대로 진행하면 됩니다.\n",
    "\n",
    "LoRA config 설정을 합니다.\n",
    "\n",
    "참고 문서에서는 특히 r, lora_alpha, lora_dropout, target_modules 항목을 중심으로, LoRA 적용 범위와 학습 효율·메모리 사용량에 미치는 영향을 확인해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "_PLkHLNkMTpC"
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.0,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]  # safe default for many LLMs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1bLeGpuMTpD"
   },
   "source": [
    "### SFTConfig 주요 설정 설명\n",
    "각 설정들은 기본적인 AI에 대한 지식이 필요한 부분들이 많습니다. 따라서, 각 설정들은 하나하나 블로그 글을 참고해가며 깊이 이해해주세요.\n",
    "\n",
    "1. output_dir\n",
    "- 설명: 학습이 끝난 모델 가중치, 체크포인트, 로그를 저장할 디렉터리 (또는 Hugging Face Hub 저장소 이름)\n",
    "- 중요성: 실험 결과를 재현하거나 이어서 학습하려면 필수로 설정해야 함\n",
    "\n",
    "2. max_seq_length\n",
    "- 설명: 한 학습 샘플의 최대 토큰 길이\n",
    "- 영향:\n",
    "\t1. 길이를 크게 하면 더 긴 문장을 학습할 수 있으나 GPU 메모리 사용량 증가\n",
    "\t2. 너무 작으면 긴 문장이 잘려서 학습 품질 저하\n",
    "\n",
    "3. packing\n",
    "\t- 설명: 여러 짧은 샘플을 하나의 시퀀스로 이어 붙여(max_seq_length까지) 학습\n",
    "\t- 장점: GPU 메모리 효율 ↑, 학습 속도 ↑ (패딩 낭비 감소)\n",
    "\t- 주의점: 시퀀스 사이를 구분하는 special token(EOS 등)을 넣어야 데이터 섞임 방지\n",
    "  - PACKING 예시\n",
    "\n",
    "    데이터셋 샘플이 각각 독립된 시퀀스로 학습되고 학습할 토큰들이 짧으면 패딩이 많아집니다.\n",
    "\n",
    "    ```\n",
    "    샘플 1: [USER] 오늘 날씨 어때? [EOS] [PAD] [PAD] [PAD] ...\n",
    "    샘플 2: [USER] 내일 비 와? [EOS] [PAD] [PAD] [PAD] ...\n",
    "    샘플 3: [USER] 주말 일정 보여줘 [EOS] [PAD] [PAD] ...\n",
    "    ```\n",
    "    GPU는 [PAD]도 연산해야 하므로 메모리 낭비 & 속도 저하가 발생합니다.\n",
    "\n",
    "    짧은 샘플들을 이어붙이고, 샘플 사이에 EOS 같은 구분 토큰을 추가하여 최대 길이(max_seq_length)에 맞게 하나의 긴 시퀀스로 묶습니다.\n",
    "\n",
    "    Packed 시퀀스:\n",
    "    ```\n",
    "    [USER] 오늘 날씨 어때? [EOS]\n",
    "    [USER] 내일 비 와? [EOS]\n",
    "    [USER] 주말 일정 보여줘 [EOS]\n",
    "    ```\n",
    "    - 패딩이 거의 없고 GPU 연산 효율 ↑\n",
    "    - 한 시퀀스 안에서 여러 예시를 한 번에 학습 → 학습 속도 ↑\n",
    "    - `Packing=False` : `[샘플1][PAD PAD PAD] [샘플2][PAD PAD PAD]`\n",
    "    - `Packing=True` : `[샘플1][EOS][샘플2][EOS][샘플3][EOS]\t`\n",
    "\n",
    "4. num_train_epochs\n",
    "- 설명: 전체 데이터셋을 몇 번 반복해서 학습할지 결정\n",
    "- 팁: LoRA/QLoRA는 적은 Epoch(2~3)으로도 잘 수렴하는 경우가 많음\n",
    "\n",
    "5. per_device_train_batch_size\n",
    "- 설명: GPU 한 장(또는 장치 하나)에서 한 번에 처리할 샘플 개수\n",
    "- 조절 포인트: GPU 메모리에 맞춰 조절. 작게 하면 gradient_accumulation_steps로 보완 가능\n",
    "\n",
    "6. gradient_accumulation_steps\n",
    "- 설명: 여러 스텝의 그래디언트를 누적해 한 번만 역전파/가중치 업데이트\n",
    "- 장점: 작은 배치로도 큰 effective batch size 구현 가능\n",
    "- 예시: batch_size=1, grad_accum=4 → 실제 batch size = 4와 비슷한 효과\n",
    "- `gradient_accumulation_steps`은 [링크]()를 참고해주세요.\n",
    "\n",
    "7. gradient_checkpointing\n",
    "- 설명: 순전파(forward) 중 일부 중간 값을 저장하지 않고 필요할 때 다시 계산\n",
    "- 장점: GPU 메모리 절약 (특히 대형 모델 학습 시 필수)\n",
    "- 단점: 연산량 증가 → 학습 속도 소폭 느려짐\n",
    "\n",
    "8. optim\n",
    "- 설명: 사용할 옵티마이저 선택 (adamw_torch_fused는 PyTorch의 fused AdamW)\n",
    "- 장점: 일반 AdamW보다 빠르고 메모리 효율 좋음 (지원 GPU 필요)\n",
    "\n",
    "9. logging_steps\n",
    "- 설명: 몇 step마다 학습 로그를 기록할지\n",
    "- 팁: 너무 작으면 로그 과다, 너무 크면 학습 추적 힘듦 → 10~50 step 정도 권장\n",
    "\n",
    "10. save_strategy\n",
    "- 설명: 모델 체크포인트 저장 시점 (epoch, steps, no)\n",
    "- 예시: \"epoch\" → 각 epoch가 끝날 때마다 저장\n",
    "\n",
    "11. learning_rate\n",
    "- 설명: 모델 학습률\n",
    "- 팁: QLoRA 논문에서 2e-4가 안정적이라고 권장\n",
    "- 주의: 지나치게 높으면 loss 폭주, 낮으면 학습 느림\n",
    "\n",
    "12. fp16 / bf16\n",
    "- 설명: 학습 시 연산 정밀도 선택\n",
    "- fp16: 대부분 GPU 지원, 메모리 절약, 속도 빠름\n",
    "- bf16: 최신 GPU(Ampere 이상)에서 권장, 안정성 더 좋음\n",
    "- 팁: Colab A100/T4 → fp16 / A100(Ampere) 이상 → bf16 추천\n",
    "\n",
    "13. max_grad_norm\n",
    "- 설명: Gradient clipping 값 (너무 큰 gradient를 잘라 학습 안정화)\n",
    "- QLoRA 권장값: 0.3\n",
    "\n",
    "14. warmup_ratio\n",
    "- 설명: 학습 초기에 learning rate를 천천히 올리는 비율\n",
    "- 장점: 학습 안정화, 초기 손실 폭주 방지\n",
    "- QLoRA 논문 값: 0.03 (~3% 단계는 warmup)\n",
    "\n",
    "15. lr_scheduler_type\n",
    "- 설명: 학습률 스케줄링 방식\n",
    "- constant: 학습 내내 일정한 학습률\n",
    "- (다른 옵션: linear, cosine 등)\n",
    "\n",
    "16. push_to_hub\n",
    "- 설명: 학습이 끝난 모델을 Hugging Face Hub에 자동 업로드할지 여부\n",
    "- 협업/공유: 팀원이나 공개 프로젝트에 유용\n",
    "\n",
    "17. report_to\n",
    "- 설명: 학습 메트릭을 어디로 보낼지 (예: \"tensorboard\", \"wandb\")\n",
    "- 장점: 학습 과정 시각화 가능\n",
    "\n",
    "학습 설정을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tyxC_iEMZ5pW",
    "outputId": "6f7eec09-4ae5-47f4-a033-e419c2d4e574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting trl\n",
      "  Downloading trl-0.28.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: accelerate>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from trl) (1.12.0)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from trl) (4.0.0)\n",
      "Requirement already satisfied: packaging>20.0 in /usr/local/lib/python3.12/dist-packages (from trl) (26.0)\n",
      "Requirement already satisfied: transformers>=4.56.2 in /usr/local/lib/python3.12/dist-packages (from trl) (5.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (2.0.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (2.10.0+cu128)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (1.4.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (0.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (3.24.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (4.67.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.56.2->trl) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.56.2->trl) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers>=4.56.2->trl) (0.24.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.13.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (1.5.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2026.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.1.6)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch>=2.0.0->accelerate>=1.4.0->trl) (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.3)\n",
      "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers>=4.56.2->trl) (0.24.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.22.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (4.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers>=4.56.2->trl) (8.3.1)\n",
      "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers>=4.56.2->trl) (13.9.4)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers>=4.56.2->trl) (0.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers>=4.56.2->trl) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers>=4.56.2->trl) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->transformers>=4.56.2->trl) (0.1.2)\n",
      "Downloading trl-0.28.0-py3-none-any.whl (540 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.5/540.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: trl\n",
      "Successfully installed trl-0.28.0\n"
     ]
    }
   ],
   "source": [
    "# AI 훈련 도구 다시 강제 주입!\n",
    "!pip install -U trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NNU2cMBqMTpD",
    "outputId": "80f05595-36a4-4c02-8113-821cbd1322d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warmup_ratio is deprecated and will be removed in v5.2. Use `warmup_steps` instead.\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "output_dir = \"outputs\"\n",
    "num_train_epochs=1\n",
    "per_device_train_batch_size = 4 # GPU가 부족하다면 해당 값을 줄여주세요.\n",
    "gradient_accumulation_steps = 4\n",
    "warmup_ratio = 0.03\n",
    "max_steps = 100 # 학습 시간이 오래 걸린다면 해당 값을 줄여주세요.\n",
    "learning_rate = 2e-5\n",
    "logging_steps = 1\n",
    "weight_decay = 0.01\n",
    "max_grad_norm=1.0\n",
    "lr_scheduler_type = \"linear\"\n",
    "report_to = \"none\" # Use this for WandB etc\n",
    "bf16=False\n",
    "gradient_checkpointing=False\n",
    "optim=\"adamw_torch\"\n",
    "\n",
    "train_cfg = SFTConfig(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    weight_decay=weight_decay,\n",
    "    logging_steps=logging_steps,\n",
    "    save_steps=max_steps,\n",
    "    max_steps=max_steps,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    report_to=report_to,\n",
    "    gradient_checkpointing=gradient_checkpointing,\n",
    "    optim=optim,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7wK6RFbMTpD"
   },
   "source": [
    "학습을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hXlnFESxMTpD",
    "outputId": "772bae82-e0e1-4163-8cf0-3bf3c3062b66"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/peft/mapping_func.py:72: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:285: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    train_dataset = train_dataset.select(range(max_steps * per_device_train_batch_size)), # max_steps * batch_size 만큼만 학습합니다.\n",
    "    peft_config=peft_config,\n",
    "    args = train_cfg,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "6uASnc30bKqm"
   },
   "outputs": [],
   "source": [
    "# 반드시 fp16은 True, bf16은 False여야 합니다!\n",
    "train_cfg.fp16 = True\n",
    "train_cfg.bf16 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_k2339jORRjT",
    "outputId": "85fd1704-5603-4a73-b1ec-3aa53a245cca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 16:52, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.126898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.374540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.703796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.980945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.894700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.146062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.169174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.677753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.959607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.070188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.809692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.872555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.923442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.071148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.192372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.613750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.497411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.882540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.871339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.847173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.669177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.885090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.874714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.981584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.704077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.721780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.049191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.450784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.816030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.782021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.752514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.498805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.633882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.645773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.550268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.555973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.667481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.571095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.421780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.571738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.658061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.753377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.379044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.590519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.479370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.529009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.383547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.479896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.236206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.305525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.239539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.197662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.449507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.425984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.301253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.364311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.433941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.395427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.360366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.188414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>1.182521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.198377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1.361338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1.112690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.186516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>1.265607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>1.159090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>1.116771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>1.443454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.147286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>1.287001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.086470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>1.031055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>1.248731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.287747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>1.075389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.986506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>1.041522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>1.262572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.290555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>1.121371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>1.345378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>1.098991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>1.274678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.145331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>1.230816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>1.266074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>1.266123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>1.206222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.192231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>1.303226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>1.245321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>1.166723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>1.243765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.186572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>1.211889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>1.037671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>1.157578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.940208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.105854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainOutput(global_step=100, training_loss=1.5115701740980148, metrics={'train_runtime': 1024.3027, 'train_samples_per_second': 1.562, 'train_steps_per_second': 0.098, 'total_flos': 2415798587572224.0, 'train_loss': 1.5115701740980148})\n",
      "=== 학습 효율성 측정 결과 ===\n",
      "학습 시간 (초): 1025.09\n",
      "초당 스텝 수: 0.098\n"
     ]
    }
   ],
   "source": [
    "# === 학습 효율성 측정 코드 ===\n",
    "import time\n",
    "import torch\n",
    "\n",
    "def measure_training_efficiency(trainer, max_steps):\n",
    "    \"\"\"LoRA vs QLoRA 효율성 비교를 위한 측정 함수\"\"\"\n",
    "\n",
    "    # 학습 시간 측정\n",
    "    start_time = time.time()\n",
    "    trainer_stats = trainer.train()\n",
    "    print(trainer_stats)\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    return {\n",
    "        \"학습 시간 (초)\": round(training_time, 2),\n",
    "        \"초당 스텝 수\": round(max_steps / training_time, 3),\n",
    "    }\n",
    "\n",
    "# 결과 출력\n",
    "results = measure_training_efficiency(trainer, max_steps)\n",
    "print(\"=== 학습 효율성 측정 결과 ===\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7vNtpLDRD4x"
   },
   "source": [
    "스켈레톤 1에서는 약 2분 내에 학습이 끝났지만, 스켈레톤 2에서는 약 6분 이상의 학습 시간이 걸립니다.\n",
    "\n",
    "QLoRA는 더 큰 모델을 학습할 수 있지만, 양자화와 역양자화를 거치기 때문에 학습시간이 엄청나게 비효율적으로 증가하게 됩니다.\n",
    "\n",
    "또한, 메모리를 체크해보면면 학습 메모리는 스켈레톤 2와 크게 달라지지 않았지만, 큰 모델을 학습시킬 수 있다는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5tQevPeqRD4x",
    "outputId": "82054c3a-c1f8-4333-be39-90578444659a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 24 02:43:24 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   62C    P0             30W /   70W |    5933MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A             882      C   /usr/bin/python3                       5930MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIBPKT2tRD4y"
   },
   "source": [
    "LoRA를 저장하는 방식은 두가지가 있습니다.\n",
    "1. base model에 LoRA weight를 merge해서 저장하는 방식\n",
    "2. LoRA weight만 따로 저장하는 방식\n",
    "\n",
    "두 방식 모두 가능하지만, 여기서는 2번 방식으로 진행하겠습니다. 많은 학습을 돌린다면 1번보다는 2번이 더욱 비용 효율적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "8qORft1cMTpD"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Save LoRA adapter (small)\n",
    "# ============================================\n",
    "merge_and_save = False\n",
    "if merge_and_save:\n",
    "    trainer.model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(f\"LoRA adapter saved to: {output_dir}\")\n",
    "\n",
    "# ============================================\n",
    "# (Optional) Merge LoRA into base weights and save a full model\n",
    "# WARNING: creates a large model; only do this if you need standalone weights\n",
    "# ============================================\n",
    "if merge_and_save:\n",
    "    from peft import AutoPeftModelForCausalLM\n",
    "    merged_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "        output_dir,\n",
    "        torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float16,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    merged_model = merged_model.merge_and_unload()\n",
    "    merged_dir = output_dir + \"-merged\"\n",
    "    merged_model.save_pretrained(merged_dir, safe_serialization=True)\n",
    "    tokenizer.save_pretrained(merged_dir)\n",
    "    print(f\"Merged full model saved to: {merged_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uR6oXaK5MTpD"
   },
   "source": [
    "모델 결과물이 잘 나오는지 테스트를 진행합니다. 우선 학습 데이터로 학습이 잘 되었는지 확인만 해보고 실제 모델의 테스트는 평가를 통해 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Ku5T0enMTpD",
    "outputId": "69af388e-3e1b-4ec9-dd72-5fd4da6e7770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답 : SELECT T2.company_name FROM movie AS T1 JOIN culture_company AS T2 ON T1.movie_id  =  T2.movie_id WHERE T1.year  =  1999\n",
      "\n",
      "SELECT company_name FROM company_movies WHERE year = 1999 AND movie_name = 'The Matrix'<|im_end|>\n",
      "\n",
      "==================================================\n",
      "📊 추론 속도 측정 결과\n",
      "==================================================\n",
      "⏱️  총 추론 시간: 7.304초\n",
      "📥 입력 토큰 수: 105개\n",
      "📤 생성 토큰 수: 27개\n",
      "🚀 토큰 생성 속도: 3.70 tokens/sec\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "text_idx = len(train_df) - 1\n",
    "\n",
    "test_input = [\n",
    "    {'role': 'system', 'content': system_prompt},\n",
    "    {'role': 'user', 'content': user_prompt.format(question=train_df[\"question\"][text_idx])},\n",
    "]\n",
    "print(\"정답 :\", train_df[\"query\"][text_idx])\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(test_input, add_generation_prompt=True, return_dict=True, return_tensors=\"pt\")\n",
    "input_prompt = tokenizer.apply_chat_template(test_input, add_generation_prompt=True, tokenize=False)\n",
    "\n",
    "# 추론 속도 측정 시작\n",
    "torch.cuda.synchronize()  # GPU 작업 완료 대기\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        **inputs.to(\"cuda\"),\n",
    "        max_new_tokens=128,\n",
    "        stop_strings=[\"<|endofturn|>\", \"<|stop|>\"],\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "# 추론 속도 측정 종료\n",
    "torch.cuda.synchronize()  # GPU 작업 완료 대기\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "# 추론 시간 계산\n",
    "inference_time = end_time - start_time\n",
    "input_token_count = inputs[\"input_ids\"].shape[1]\n",
    "output_token_count = output_ids.shape[1]\n",
    "generated_token_count = output_token_count - input_token_count\n",
    "tokens_per_second = generated_token_count / inference_time\n",
    "\n",
    "print(tokenizer.batch_decode(output_ids)[0][len(input_prompt) - 1:])\n",
    "\n",
    "# 추론 속도 출력\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"📊 추론 속도 측정 결과\")\n",
    "print(\"=\"*50)\n",
    "print(f\"⏱️  총 추론 시간: {inference_time:.3f}초\")\n",
    "print(f\"📥 입력 토큰 수: {input_token_count}개\")\n",
    "print(f\"📤 생성 토큰 수: {generated_token_count}개\")\n",
    "print(f\"🚀 토큰 생성 속도: {tokens_per_second:.2f} tokens/sec\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BiwRmmbeiocx",
    "outputId": "893a6787-2e70-47c7-db0d-e315dca2b48d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/outputs/ (stored 0%)\n",
      "  adding: content/outputs/checkpoint-100/ (stored 0%)\n",
      "  adding: content/outputs/checkpoint-100/rng_state.pth (deflated 26%)\n",
      "  adding: content/outputs/checkpoint-100/tokenizer_config.json (deflated 49%)\n",
      "  adding: content/outputs/checkpoint-100/optimizer.pt (deflated 21%)\n",
      "  adding: content/outputs/checkpoint-100/training_args.bin (deflated 53%)\n",
      "  adding: content/outputs/checkpoint-100/chat_template.jinja (deflated 42%)\n",
      "  adding: content/outputs/checkpoint-100/tokenizer.json (deflated 82%)\n",
      "  adding: content/outputs/checkpoint-100/scheduler.pt (deflated 62%)\n",
      "  adding: content/outputs/checkpoint-100/adapter_config.json (deflated 58%)\n",
      "  adding: content/outputs/checkpoint-100/trainer_state.json (deflated 81%)\n",
      "  adding: content/outputs/checkpoint-100/README.md (deflated 65%)\n",
      "  adding: content/outputs/checkpoint-100/adapter_model.safetensors (deflated 23%)\n",
      "  adding: content/outputs/README.md (deflated 43%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /content/trained_model.zip /content/outputs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDtqlk2mRD4y"
   },
   "source": [
    "이제 모델 성능을 평가해봅시다.\n",
    "\n",
    "### step 1.\n",
    "모델 성능을 평가하기 이전에 jupyter notebook은 커널을 계속 실행하고 있기 때문에 jupyter notebook을 `restart`를 해야만 jupyter notebook에서 사용하는 GPU가 비워집니다.\n",
    "\n",
    "꼭 jupyter notebook을 비우고 `python inference.py` 명령어를 실행해주세요. `outputs/` 디렉토리가 있다면 LoRA 모델을 먼저 불러오게끔 설정이 되어 있습니다.\n",
    "\n",
    "Powershell 혹은 bash에서 스크립트를 실행하게 되는데 가상환경을 꼭 실행하고 진행해주세요.\n",
    "```bash\n",
    "source .venv/Scripts/activate\n",
    "```\n",
    "\n",
    "### step 2.\n",
    "아래 명령어로 inference.py를 돌리실 수 있습니다.\n",
    "```bash\n",
    "python inference.py\n",
    "```\n",
    "\n",
    "### step 3.\n",
    "\n",
    "inference를 돌린 이후에는\n",
    "```bash\n",
    "cd test-suite-sql-eval-master\n",
    "python evaluation.py --gold gold.txt --pred predict.txt --db database/ --etype exec --plug_value\n",
    "```\n",
    "명령어로 평가를 직접 진행해보시길 바랍니다."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01364f75e7954b56a0dd550cdc2fddf7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "036dd3db9d8f440f93d8d28794b1513b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "044fded498ec4bcead698e9a6da8974d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_50715a964d754a918ae83ce42e67fb86",
       "IPY_MODEL_491fba4d1de2420ba9814942895a445b",
       "IPY_MODEL_83fd4d32b8e44477a1f7dd01bb542509"
      ],
      "layout": "IPY_MODEL_2eeb00ca664148b58861ad209f7b9ef3"
     }
    },
    "09f3104619644a5cb928529c956b27af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0d92915a464c44e9aad59b47b5f7b8f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "135e724c58c246debb09335db3192adf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ede1aa1a04f14f75ab3912c158414994",
      "placeholder": "​",
      "style": "IPY_MODEL_cc6be34c3bf546a79eb52ce4c0d10f04",
      "value": "model.safetensors: 100%"
     }
    },
    "150ad363a34d47fcbf397bc0100266d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1748d11529aa4b7d8f0d36a1d9f96c1e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bcd4a36d6da4caa9de4bd887ee9756f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48ddd55c3cfb4568b2af671bcfc26e23",
      "placeholder": "​",
      "style": "IPY_MODEL_7381ebc661934b8f9d99222328236c49",
      "value": " 3.76k/? [00:00&lt;00:00, 161kB/s]"
     }
    },
    "1cdb36b9ca4d47e8852f92a3144f08d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "204803f7eda44d348c1726addcb1fd6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4838c4ddb2f4252b008390026e752a3",
      "max": 655,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_949bd51bd1804c1a8b38d7336bed96b9",
      "value": 655
     }
    },
    "2587ce3c328c4387ad73e3806e68e9b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29a9f4ba9d4b464d975e351fdc4fc71e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2beeb9f426e840eb9b4c442a6c474aa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5f08d91933ac4b8d8565aaacb663d16b",
       "IPY_MODEL_204803f7eda44d348c1726addcb1fd6b",
       "IPY_MODEL_f06107d37d8643369cc87ece65ee16ed"
      ],
      "layout": "IPY_MODEL_0d92915a464c44e9aad59b47b5f7b8f3"
     }
    },
    "2e3ce1f497cd4775b128587b628163ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_efe22d32821a4958a28c2ba4bee9253e",
       "IPY_MODEL_c26b27fab0dc47c6b6e852274724816f",
       "IPY_MODEL_e9839cedbf8c4a698401202b5e0e6faf"
      ],
      "layout": "IPY_MODEL_01364f75e7954b56a0dd550cdc2fddf7"
     }
    },
    "2eeb00ca664148b58861ad209f7b9ef3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35bec85303f349c3bb5c533dda215bc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3ed14dc411245d7881e6f2eeaf094ff",
      "placeholder": "​",
      "style": "IPY_MODEL_90ab95ef5fea460196506702c11c8631",
      "value": "tokenizer_config.json: "
     }
    },
    "3c843cd3d9ec4e5f8c4af54fcd94e97e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4273328d19d243c79041e9031ee92c39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6adea437666c485bbf9391b082227f5e",
      "placeholder": "​",
      "style": "IPY_MODEL_71aad6bc688043a69c831dd303a09c8d",
      "value": "tokenizer.json: "
     }
    },
    "48ddd55c3cfb4568b2af671bcfc26e23": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "491fba4d1de2420ba9814942895a445b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_29a9f4ba9d4b464d975e351fdc4fc71e",
      "max": 908,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8c1eb142280a424eaa80a50a7cf671a7",
      "value": 908
     }
    },
    "49d6e6daa3a2451982f4580bc38e2dfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_135e724c58c246debb09335db3192adf",
       "IPY_MODEL_8d285d4b02a744ee93dff79a7ddce753",
       "IPY_MODEL_aec3a9b783b04959a31b8626510cf657"
      ],
      "layout": "IPY_MODEL_606abf9dc002499fa82d132757d33ad7"
     }
    },
    "50715a964d754a918ae83ce42e67fb86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5171ec61d115445fa747a7057351f8e1",
      "placeholder": "​",
      "style": "IPY_MODEL_599a05b923a248c59199736d54eba52a",
      "value": "config.json: 100%"
     }
    },
    "5171ec61d115445fa747a7057351f8e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57fdf0bf266e4054922c36fde8b1cfab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4273328d19d243c79041e9031ee92c39",
       "IPY_MODEL_d8696f1ab58b40069809703930c29395",
       "IPY_MODEL_af11b3c291a84efc9f203b3f4f34ea7a"
      ],
      "layout": "IPY_MODEL_a952f9c01d03444c96111dcf4d9b1c16"
     }
    },
    "599a05b923a248c59199736d54eba52a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d4075e49a5146e6a8a0c0b111ede33b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f08d91933ac4b8d8565aaacb663d16b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_790b5a9a3529470da9b5d118cb87edfd",
      "placeholder": "​",
      "style": "IPY_MODEL_6ab78542fc1c44dca276e24136bbc10d",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "606abf9dc002499fa82d132757d33ad7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60b9065693644a918713667d686a5aa4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ab78542fc1c44dca276e24136bbc10d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6adea437666c485bbf9391b082227f5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6df14f969b83492684a789491fe28912": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fb8bbb4a17547ea8fe7d8d8b4c22c61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71aad6bc688043a69c831dd303a09c8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "73503c5b8af04bc3a5e76d1229bfdb9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7381ebc661934b8f9d99222328236c49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "745337323b2241ce9a30e115a55a00eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74564b0783ae4a68acfab4ec95a19a8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6841f7227b3487ba98ee4523b6d23d8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e069bd14baad44f5aba6caca5f2d4a8b",
      "value": 1
     }
    },
    "75519921c3a342ed96a21adb010cc3fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "777338b434d942edb0fbe2e26716aeac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "790b5a9a3529470da9b5d118cb87edfd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e4297650a2243848e8c539f6cbe634e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6df14f969b83492684a789491fe28912",
      "placeholder": "​",
      "style": "IPY_MODEL_150ad363a34d47fcbf397bc0100266d0",
      "value": "Loading weights: 100%"
     }
    },
    "83fd4d32b8e44477a1f7dd01bb542509": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d4075e49a5146e6a8a0c0b111ede33b",
      "placeholder": "​",
      "style": "IPY_MODEL_09f3104619644a5cb928529c956b27af",
      "value": " 908/908 [00:00&lt;00:00, 30.9kB/s]"
     }
    },
    "8c1eb142280a424eaa80a50a7cf671a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8d285d4b02a744ee93dff79a7ddce753": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_745337323b2241ce9a30e115a55a00eb",
      "max": 3422777952,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c173c1b765a74af09b0152cba06a1d86",
      "value": 3422777952
     }
    },
    "90ab95ef5fea460196506702c11c8631": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "924fe9bec1cd4c55a7b2573d4adbb71f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "94917f9ba7e04d27b45fbe7a7235f714": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "949bd51bd1804c1a8b38d7336bed96b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a4838c4ddb2f4252b008390026e752a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8441f5918aa41238d1f9806bec5d8e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a849dde45f5242f6af508085bba565cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1748d11529aa4b7d8f0d36a1d9f96c1e",
      "max": 218,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b87c049e6a3d4d77990872187d24350a",
      "value": 218
     }
    },
    "a952f9c01d03444c96111dcf4d9b1c16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aec3a9b783b04959a31b8626510cf657": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2587ce3c328c4387ad73e3806e68e9b8",
      "placeholder": "​",
      "style": "IPY_MODEL_c3628e99ee4e493daa5f16c89db11ec0",
      "value": " 3.42G/3.42G [00:36&lt;00:00, 186MB/s]"
     }
    },
    "af11b3c291a84efc9f203b3f4f34ea7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60b9065693644a918713667d686a5aa4",
      "placeholder": "​",
      "style": "IPY_MODEL_3c843cd3d9ec4e5f8c4af54fcd94e97e",
      "value": " 2.10M/? [00:00&lt;00:00, 13.9MB/s]"
     }
    },
    "b5bd73b0c3af48f0999ff19ee5d15ceb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b87c049e6a3d4d77990872187d24350a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b9472d5fbfdf4eda8820f3d5dbf9142a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf245b3f121d4324a3c70a5813c1cb04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7e4297650a2243848e8c539f6cbe634e",
       "IPY_MODEL_a849dde45f5242f6af508085bba565cc",
       "IPY_MODEL_c5739bc6e6fb4b2db368fbe1f6cd925f"
      ],
      "layout": "IPY_MODEL_b5bd73b0c3af48f0999ff19ee5d15ceb"
     }
    },
    "c173c1b765a74af09b0152cba06a1d86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c26b27fab0dc47c6b6e852274724816f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_036dd3db9d8f440f93d8d28794b1513b",
      "max": 132,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_777338b434d942edb0fbe2e26716aeac",
      "value": 132
     }
    },
    "c3628e99ee4e493daa5f16c89db11ec0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c4ccd282069d4d0c95589b49cefb5b67": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5739bc6e6fb4b2db368fbe1f6cd925f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c4ccd282069d4d0c95589b49cefb5b67",
      "placeholder": "​",
      "style": "IPY_MODEL_924fe9bec1cd4c55a7b2573d4adbb71f",
      "value": " 218/218 [00:08&lt;00:00, 159.89it/s, Materializing param=model.norm.weight]"
     }
    },
    "cc6be34c3bf546a79eb52ce4c0d10f04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd0c4c6a640142bc8ff0a10bb85922ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8696f1ab58b40069809703930c29395": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94917f9ba7e04d27b45fbe7a7235f714",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e5f370e096ad48e9a62babb4bbdbe9ac",
      "value": 1
     }
    },
    "e069bd14baad44f5aba6caca5f2d4a8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e3ed14dc411245d7881e6f2eeaf094ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5f370e096ad48e9a62babb4bbdbe9ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e6841f7227b3487ba98ee4523b6d23d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "e9839cedbf8c4a698401202b5e0e6faf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6fb8bbb4a17547ea8fe7d8d8b4c22c61",
      "placeholder": "​",
      "style": "IPY_MODEL_1cdb36b9ca4d47e8852f92a3144f08d9",
      "value": " 132/132 [00:00&lt;00:00, 4.86kB/s]"
     }
    },
    "ede1aa1a04f14f75ab3912c158414994": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efe22d32821a4958a28c2ba4bee9253e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd0c4c6a640142bc8ff0a10bb85922ea",
      "placeholder": "​",
      "style": "IPY_MODEL_75519921c3a342ed96a21adb010cc3fb",
      "value": "generation_config.json: 100%"
     }
    },
    "f06107d37d8643369cc87ece65ee16ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73503c5b8af04bc3a5e76d1229bfdb9a",
      "placeholder": "​",
      "style": "IPY_MODEL_b9472d5fbfdf4eda8820f3d5dbf9142a",
      "value": " 655/655 [00:00&lt;00:00, 16.8kB/s]"
     }
    },
    "f8d73361f8494980803b4753ce57cded": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_35bec85303f349c3bb5c533dda215bc3",
       "IPY_MODEL_74564b0783ae4a68acfab4ec95a19a8c",
       "IPY_MODEL_1bcd4a36d6da4caa9de4bd887ee9756f"
      ],
      "layout": "IPY_MODEL_a8441f5918aa41238d1f9806bec5d8e5"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
